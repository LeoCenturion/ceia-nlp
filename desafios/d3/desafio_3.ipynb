{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3c6500-5d23-4f0a-a706-0daf1d25eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 10:48:26.043177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749390506.072496  194450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749390506.077104  194450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749390506.129722  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749390506.129747  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749390506.129751  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749390506.129754  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-08 10:48:26.136112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homer_-_The_Iliad.txt\n",
      "Homer_-_The_Odyssey.txt\n",
      "Plato_-_Charmides.txt\n",
      "Plato_-_Lysis.txt\n",
      "Plato_-_Laches.txt\n",
      "Plato_-_Protagoras.txt\n",
      "Plato_-_Euthydemus.txt\n",
      "Plato_-_Cratylus.txt\n",
      "Plato_-_Phaedrus.txt\n",
      "Plato_-_Ion.txt\n",
      "Plato_-_Symposium.txt\n",
      "Plato_-_Meno.txt\n",
      "Plato_-_Euthyphro.txt\n",
      "Plato_-_Apology.txt\n",
      "Plato_-_Crito.txt\n",
      "Plato_-_Phaedo.txt\n",
      "Plato_-_Gorgias.txt\n",
      "Plato_-_The_Republic.txt\n",
      "Plato_-_Timaeus.txt\n",
      "Plato_-_Critias.txt\n",
      "Plato_-_Parmenides.txt\n",
      "Plato_-_Theaetetus.txt\n",
      "Plato_-_Sophist.txt\n",
      "Plato_-_Statesman.txt\n",
      "Plato_-_Philebus.txt\n",
      "Plato_-_Laws.txt\n",
      "Aristotle_-_Categories.txt\n",
      "Aristotle_-_Physics.txt\n",
      "Aristotle_-_On_the_Heavens.txt\n",
      "Aristotle_-_On_Dreams.txt\n",
      "Aristotle_-_History_of_Animals.txt\n",
      "Aristotle_-_Politics.txt\n",
      "Aristotle_-_The_Athenian_Constitution.txt\n",
      "Aristotle_-_Rhetoric.txt\n",
      "Aristotle_-_Poetics.txt\n",
      "Aristotle_-_On_the_Soul.txt\n",
      "Aristotle_-_Nicomachean_Ethics.txt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "corpus_path = '../gutenberg_ebooks/'\n",
    "text = \"\"\n",
    "count = 0\n",
    "for filename in os.listdir(corpus_path):\n",
    "    if filename.endswith(\".txt\") and (\"Aristotle\" in filename or \"Plato\" in filename or \"Homer\" in filename):\n",
    "        with open(os.path.join(corpus_path, filename), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text += f.read().lower()\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656ec8be-b98f-4e3a-ae7b-90993d60c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33cdb5-86b6-4103-8dc1-10494cde5cca",
   "metadata": {},
   "source": [
    "# Arquitectura simple: Emb -> LSTM -> Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc20f3-bd98-4327-bafa-9807943be2a0",
   "metadata": {},
   "source": [
    "## Tokenizacion por palabra\n",
    "\n",
    "Aplicaremos tokenizacion por palabra. Vamos a restringir el vocabulario a los 5000 primeros tokens que concentran la mayoria de las apariciones. Eso, esperamos, ayude a tener un mejor accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0fde890b-f2e9-4131-8df6-d9a5c627507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def build_word_sliding_windows(text_corpus, seq_length = 10, step = 1):\n",
    "    \n",
    "    tokenizer = Tokenizer(oov_token=\"<unk>\", num_words=5000)\n",
    "    tokenizer.fit_on_texts([text_corpus])\n",
    "    \n",
    "    word_to_int = tokenizer.word_index\n",
    "    int_to_word = tokenizer.index_word\n",
    "    # vocab_size = len(word_to_int) + 1\n",
    "    vocab_size = 5000 + 1\n",
    "    \n",
    "    int_text_tokens = tokenizer.texts_to_sequences([text_corpus])[0]\n",
    "    \n",
    "    sequences = []\n",
    "    next_words = []\n",
    "    \n",
    "    for i in range(0, len(int_text_tokens) - seq_length, step):\n",
    "        sequences.append(int_text_tokens[i: i + seq_length])\n",
    "        next_words.append(int_text_tokens[i + seq_length])\n",
    "    \n",
    "    if not sequences:\n",
    "        exit()\n",
    "    \n",
    "    x = np.array(sequences)\n",
    "    y = np.array(next_words)\n",
    "    \n",
    "    return x, y, vocab_size\n",
    "\n",
    "def generate_text(model, start_string, num_generate=50, temperature=1.0): # num_generate is number of words\n",
    "    start_string_processed = start_string.lower() # Tokenizer is case-sensitive by default unless lower=True\n",
    "    \n",
    "    tokenized_start_string = tokenizer.texts_to_sequences([start_string_processed])[0]\n",
    "\n",
    "    history = [0] * seq_length # Initialize with padding token (0)\n",
    "    \n",
    "    if len(tokenized_start_string) >= seq_length:\n",
    "        history = tokenized_start_string[-seq_length:]\n",
    "    else:\n",
    "        history[-len(tokenized_start_string):] = tokenized_start_string\n",
    "    \n",
    "    input_eval = tf.expand_dims(history, 0)\n",
    "\n",
    "    generated_words_list = []\n",
    "    # model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        predictions_from_model = model(input_eval)\n",
    "        \n",
    "        scaled_logits = predictions_from_model / temperature\n",
    "        predicted_id_tensor = tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        predicted_id = predicted_id_tensor[0, 0].numpy()\n",
    "        \n",
    "        # Handle potential prediction of padding token (index 0) or OOV if necessary\n",
    "        # Though ideally, the model shouldn't predict padding if not in target data.\n",
    "        # OOV token index is tokenizer.word_index[tokenizer.oov_token]\n",
    "        # If predicted_id is 0 (padding), we might want to re-sample or pick a high prob word.\n",
    "        # For simplicity here, we use what's predicted.\n",
    "        word = int_to_word.get(predicted_id, tokenizer.oov_token if tokenizer.oov_token else \"<unk>\")\n",
    "        \n",
    "        generated_words_list.append(word)\n",
    "        \n",
    "        history.append(predicted_id)\n",
    "        history = history[1:] # Slide the window\n",
    "        \n",
    "        input_eval = tf.expand_dims(history, 0)\n",
    "\n",
    "    return start_string + \" \" + \" \".join(generated_words_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5a63834f-8f06-4edd-b694-dc9c25e42573",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<unk>\", num_words=5000)\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "word_to_int = tokenizer.word_index\n",
    "int_to_word = tokenizer.index_word\n",
    "vocab_size = len(word_to_int) + 1\n",
    "\n",
    "int_text_tokens = tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aea68fd6-2ecf-4ece-a99c-e9d702962be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51227"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7bc008f2-5298-4590-b134-5375a635739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000e+00 5.0080e+02 1.0006e+03 1.5004e+03 2.0002e+03 2.5000e+03\n",
      " 2.9998e+03 3.4996e+03 3.9994e+03 4.4992e+03 4.9990e+03]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "hist, edges = np.histogram(int_text_tokens)\n",
    "print(edges)\n",
    "plt.hist(int_text_tokens, bins=edges)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2bd79512-e1ba-4778-909d-5f71fb0fe221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.1290 - loss: 5.7916 - val_accuracy: 0.2155 - val_loss: 5.0395\n",
      "Epoch 2/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.2055 - loss: 4.7689 - val_accuracy: 0.2233 - val_loss: 4.8716\n",
      "Epoch 3/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.2273 - loss: 4.5146 - val_accuracy: 0.2315 - val_loss: 4.7641\n",
      "Epoch 4/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.2441 - loss: 4.3588 - val_accuracy: 0.2347 - val_loss: 4.6837\n",
      "Epoch 5/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.2551 - loss: 4.2547 - val_accuracy: 0.2391 - val_loss: 4.6163\n",
      "Epoch 6/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2618 - loss: 4.1769 - val_accuracy: 0.2420 - val_loss: 4.5482\n",
      "Epoch 7/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.2674 - loss: 4.1124 - val_accuracy: 0.2466 - val_loss: 4.4979\n",
      "Epoch 8/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2719 - loss: 4.0625 - val_accuracy: 0.2478 - val_loss: 4.4531\n",
      "Epoch 9/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2754 - loss: 4.0143 - val_accuracy: 0.2487 - val_loss: 4.4277\n",
      "Epoch 10/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.2781 - loss: 3.9777 - val_accuracy: 0.2549 - val_loss: 4.3777\n",
      "Epoch 11/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.2809 - loss: 3.9445 - val_accuracy: 0.2552 - val_loss: 4.3510\n",
      "Epoch 12/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.2829 - loss: 3.9124 - val_accuracy: 0.2561 - val_loss: 4.3304\n",
      "Epoch 13/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.2855 - loss: 3.8835 - val_accuracy: 0.2591 - val_loss: 4.2963\n",
      "Epoch 14/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.2870 - loss: 3.8581 - val_accuracy: 0.2606 - val_loss: 4.2732\n",
      "Epoch 15/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.2892 - loss: 3.8327 - val_accuracy: 0.2632 - val_loss: 4.2439\n",
      "Epoch 16/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2910 - loss: 3.8095 - val_accuracy: 0.2654 - val_loss: 4.2222\n",
      "Epoch 17/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2929 - loss: 3.7888 - val_accuracy: 0.2643 - val_loss: 4.2005\n",
      "Epoch 18/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2953 - loss: 3.7650 - val_accuracy: 0.2693 - val_loss: 4.1574\n",
      "Epoch 19/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.2968 - loss: 3.7467 - val_accuracy: 0.2702 - val_loss: 4.1456\n",
      "Epoch 20/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2990 - loss: 3.7260 - val_accuracy: 0.2723 - val_loss: 4.1203\n",
      "Epoch 21/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3005 - loss: 3.7059 - val_accuracy: 0.2746 - val_loss: 4.1000\n",
      "Epoch 22/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3021 - loss: 3.6934 - val_accuracy: 0.2718 - val_loss: 4.0841\n",
      "Epoch 23/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3032 - loss: 3.6797 - val_accuracy: 0.2735 - val_loss: 4.0736\n",
      "Epoch 24/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3045 - loss: 3.6642 - val_accuracy: 0.2789 - val_loss: 4.0462\n",
      "Epoch 25/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3066 - loss: 3.6433 - val_accuracy: 0.2747 - val_loss: 4.0271\n",
      "Epoch 26/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3075 - loss: 3.6324 - val_accuracy: 0.2796 - val_loss: 4.0025\n",
      "Epoch 27/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3091 - loss: 3.6178 - val_accuracy: 0.2806 - val_loss: 3.9989\n",
      "Epoch 28/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3105 - loss: 3.6044 - val_accuracy: 0.2843 - val_loss: 3.9762\n",
      "Epoch 29/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3122 - loss: 3.5919 - val_accuracy: 0.2863 - val_loss: 3.9559\n",
      "Epoch 30/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3134 - loss: 3.5788 - val_accuracy: 0.2838 - val_loss: 3.9469\n",
      "Epoch 31/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3151 - loss: 3.5644 - val_accuracy: 0.2846 - val_loss: 3.9197\n",
      "Epoch 32/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3163 - loss: 3.5524 - val_accuracy: 0.2864 - val_loss: 3.9176\n",
      "Epoch 33/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3174 - loss: 3.5414 - val_accuracy: 0.2927 - val_loss: 3.8981\n",
      "Epoch 34/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3184 - loss: 3.5334 - val_accuracy: 0.2907 - val_loss: 3.8883\n",
      "Epoch 35/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3197 - loss: 3.5227 - val_accuracy: 0.2880 - val_loss: 3.8830\n",
      "Epoch 36/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3204 - loss: 3.5126 - val_accuracy: 0.2896 - val_loss: 3.8654\n",
      "Epoch 37/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.3216 - loss: 3.5034 - val_accuracy: 0.2917 - val_loss: 3.8530\n",
      "Epoch 38/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3227 - loss: 3.4953 - val_accuracy: 0.2919 - val_loss: 3.8373\n",
      "Epoch 39/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3234 - loss: 3.4829 - val_accuracy: 0.2913 - val_loss: 3.8326\n",
      "Epoch 40/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3249 - loss: 3.4764 - val_accuracy: 0.2968 - val_loss: 3.8191\n",
      "Epoch 41/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3261 - loss: 3.4651 - val_accuracy: 0.2977 - val_loss: 3.8107\n",
      "Epoch 42/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3263 - loss: 3.4596 - val_accuracy: 0.2950 - val_loss: 3.8015\n",
      "Epoch 43/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3274 - loss: 3.4517 - val_accuracy: 0.2994 - val_loss: 3.7925\n",
      "Epoch 44/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3280 - loss: 3.4446 - val_accuracy: 0.3029 - val_loss: 3.7820\n",
      "Epoch 45/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3289 - loss: 3.4376 - val_accuracy: 0.3026 - val_loss: 3.7762\n",
      "Epoch 46/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3304 - loss: 3.4282 - val_accuracy: 0.3015 - val_loss: 3.7588\n",
      "Epoch 47/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3306 - loss: 3.4211 - val_accuracy: 0.3059 - val_loss: 3.7441\n",
      "Epoch 48/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3320 - loss: 3.4169 - val_accuracy: 0.3063 - val_loss: 3.7410\n",
      "Epoch 49/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3320 - loss: 3.4110 - val_accuracy: 0.3079 - val_loss: 3.7345\n",
      "Epoch 50/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3333 - loss: 3.4042 - val_accuracy: 0.3078 - val_loss: 3.7249\n",
      "Epoch 51/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3337 - loss: 3.3993 - val_accuracy: 0.3095 - val_loss: 3.7224\n",
      "Epoch 52/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3349 - loss: 3.3909 - val_accuracy: 0.3094 - val_loss: 3.7205\n",
      "Epoch 53/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3350 - loss: 3.3882 - val_accuracy: 0.3080 - val_loss: 3.7080\n",
      "Epoch 54/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3361 - loss: 3.3800 - val_accuracy: 0.3109 - val_loss: 3.6986\n",
      "Epoch 55/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3364 - loss: 3.3786 - val_accuracy: 0.3109 - val_loss: 3.6924\n",
      "Epoch 56/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3369 - loss: 3.3733 - val_accuracy: 0.3091 - val_loss: 3.6939\n",
      "Epoch 57/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3377 - loss: 3.3668 - val_accuracy: 0.3123 - val_loss: 3.6792\n",
      "Epoch 58/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3383 - loss: 3.3596 - val_accuracy: 0.3111 - val_loss: 3.6767\n",
      "Epoch 59/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3390 - loss: 3.3578 - val_accuracy: 0.3128 - val_loss: 3.6652\n",
      "Epoch 60/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3388 - loss: 3.3555 - val_accuracy: 0.3145 - val_loss: 3.6666\n",
      "Epoch 61/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3396 - loss: 3.3489 - val_accuracy: 0.3155 - val_loss: 3.6575\n",
      "Epoch 62/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3404 - loss: 3.3460 - val_accuracy: 0.3156 - val_loss: 3.6477\n",
      "Epoch 63/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.3407 - loss: 3.3408 - val_accuracy: 0.3168 - val_loss: 3.6491\n",
      "Epoch 64/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3416 - loss: 3.3337 - val_accuracy: 0.3176 - val_loss: 3.6397\n",
      "Epoch 65/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3424 - loss: 3.3308 - val_accuracy: 0.3178 - val_loss: 3.6487\n",
      "Epoch 66/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3426 - loss: 3.3287 - val_accuracy: 0.3167 - val_loss: 3.6331\n",
      "Epoch 67/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3426 - loss: 3.3232 - val_accuracy: 0.3182 - val_loss: 3.6199\n",
      "Epoch 68/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3431 - loss: 3.3199 - val_accuracy: 0.3201 - val_loss: 3.6096\n",
      "Epoch 69/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3437 - loss: 3.3176 - val_accuracy: 0.3170 - val_loss: 3.6204\n",
      "Epoch 70/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3445 - loss: 3.3123 - val_accuracy: 0.3160 - val_loss: 3.6156\n",
      "Epoch 71/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3444 - loss: 3.3133 - val_accuracy: 0.3194 - val_loss: 3.6029\n",
      "Epoch 72/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3447 - loss: 3.3092 - val_accuracy: 0.3215 - val_loss: 3.6096\n",
      "Epoch 73/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3446 - loss: 3.3071 - val_accuracy: 0.3199 - val_loss: 3.6060\n",
      "Epoch 74/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3460 - loss: 3.2982 - val_accuracy: 0.3185 - val_loss: 3.5940\n",
      "Epoch 75/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3462 - loss: 3.2982 - val_accuracy: 0.3183 - val_loss: 3.5986\n",
      "Epoch 76/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3468 - loss: 3.2935 - val_accuracy: 0.3243 - val_loss: 3.5817\n",
      "Epoch 77/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3467 - loss: 3.2925 - val_accuracy: 0.3213 - val_loss: 3.5814\n",
      "Epoch 78/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3472 - loss: 3.2938 - val_accuracy: 0.3199 - val_loss: 3.5858\n",
      "Epoch 79/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3473 - loss: 3.2860 - val_accuracy: 0.3238 - val_loss: 3.5745\n",
      "Epoch 80/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3479 - loss: 3.2840 - val_accuracy: 0.3239 - val_loss: 3.5772\n",
      "Epoch 81/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3480 - loss: 3.2827 - val_accuracy: 0.3246 - val_loss: 3.5746\n",
      "Epoch 82/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3485 - loss: 3.2792 - val_accuracy: 0.3219 - val_loss: 3.5714\n",
      "Epoch 83/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3483 - loss: 3.2767 - val_accuracy: 0.3233 - val_loss: 3.5628\n",
      "Epoch 84/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3490 - loss: 3.2747 - val_accuracy: 0.3213 - val_loss: 3.5674\n",
      "Epoch 85/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3502 - loss: 3.2683 - val_accuracy: 0.3227 - val_loss: 3.5643\n",
      "Epoch 86/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.3495 - loss: 3.2722 - val_accuracy: 0.3219 - val_loss: 3.5599\n",
      "Epoch 87/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.3494 - loss: 3.2708 - val_accuracy: 0.3259 - val_loss: 3.5467\n",
      "Epoch 88/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.3494 - loss: 3.2686 - val_accuracy: 0.3268 - val_loss: 3.5529\n",
      "Epoch 89/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.3494 - loss: 3.2700 - val_accuracy: 0.3207 - val_loss: 3.5480\n",
      "Epoch 90/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.3506 - loss: 3.2620 - val_accuracy: 0.3281 - val_loss: 3.5385\n",
      "Restoring model weights from the end of the best epoch: 90.\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text)\n",
    "\n",
    "embedding_dim = 256\n",
    "rnn_units = 128\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 1024\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c624fba-7dd1-47be-84d4-7a6d834fc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_sa_lr01.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd310864-6a7f-4514-893d-eaab0f9c4de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature 0.5:\n",
      "It was a dark and stormy night daring nourished readable execution helen euthydemus obtaining numerous outward obscure arrow satisfactory notes brazen oft 18 woman's exercises agreement attend\n",
      "\n",
      "Temperature 1.0:\n",
      "It was a dark and stormy night twelve multitude transcribe question chaerephon they analogy sees μέσα poets attached affirmed wanted δηλαδή x ctesippus plain aware bare scale\n",
      "\n",
      "Temperature 1.2 (different seed):\n",
      "The king declared majority roll’d do go anxious hymn file laches holder suddenly οποίαν answered allows assigned touch’d conquered love appeared saved beasts\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a dark and stormy night\"\n",
    "generated_output_temp_0_5 = generate_text(model, start_string=seed_text, num_generate=20, temperature=0.5)\n",
    "# To see the output, you would need to print it:\n",
    "print(f\"\\nTemperature 0.5:\\n{generated_output_temp_0_5}\")\n",
    "\n",
    "generated_output_temp_1_0 = generate_text(model, start_string=seed_text, num_generate=20, temperature=1.0)\n",
    "print(f\"\\nTemperature 1.0:\\n{generated_output_temp_1_0}\")\n",
    "\n",
    "generated_output_temp_1_5 = generate_text(model, start_string=\"The king declared\", num_generate=20, temperature=1.2)\n",
    "print(f\"\\nTemperature 1.2 (different seed):\\n{generated_output_temp_1_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a7d27-b590-4f17-9e15-da2433d53181",
   "metadata": {},
   "source": [
    "Probamos duplicando las capas de LSTM agregando dropout en el medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24839ddb-550a-4f8b-9b13-2f334ceea757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.0951 - loss: 6.1280 - val_accuracy: 0.1943 - val_loss: 5.3511\n",
      "Epoch 2/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.1690 - loss: 5.2387 - val_accuracy: 0.2126 - val_loss: 5.0599\n",
      "Epoch 3/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.1901 - loss: 4.9198 - val_accuracy: 0.2186 - val_loss: 4.9587\n",
      "Epoch 4/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2033 - loss: 4.7383 - val_accuracy: 0.2218 - val_loss: 4.8891\n",
      "Epoch 5/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2160 - loss: 4.6185 - val_accuracy: 0.2247 - val_loss: 4.8300\n",
      "Epoch 6/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2257 - loss: 4.5299 - val_accuracy: 0.2284 - val_loss: 4.7652\n",
      "Epoch 7/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2341 - loss: 4.4594 - val_accuracy: 0.2322 - val_loss: 4.7163\n",
      "Epoch 8/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2397 - loss: 4.4068 - val_accuracy: 0.2358 - val_loss: 4.6777\n",
      "Epoch 9/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2445 - loss: 4.3549 - val_accuracy: 0.2357 - val_loss: 4.6391\n",
      "Epoch 10/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2474 - loss: 4.3194 - val_accuracy: 0.2402 - val_loss: 4.5962\n",
      "Epoch 11/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2514 - loss: 4.2852 - val_accuracy: 0.2410 - val_loss: 4.5623\n",
      "Epoch 12/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2540 - loss: 4.2524 - val_accuracy: 0.2437 - val_loss: 4.5319\n",
      "Epoch 13/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2557 - loss: 4.2303 - val_accuracy: 0.2453 - val_loss: 4.5135\n",
      "Epoch 14/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2583 - loss: 4.2030 - val_accuracy: 0.2453 - val_loss: 4.4904\n",
      "Epoch 15/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2591 - loss: 4.1854 - val_accuracy: 0.2470 - val_loss: 4.4704\n",
      "Epoch 16/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2602 - loss: 4.1682 - val_accuracy: 0.2497 - val_loss: 4.4410\n",
      "Epoch 17/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2616 - loss: 4.1528 - val_accuracy: 0.2527 - val_loss: 4.4243\n",
      "Epoch 18/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2628 - loss: 4.1332 - val_accuracy: 0.2535 - val_loss: 4.3963\n",
      "Epoch 19/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2638 - loss: 4.1218 - val_accuracy: 0.2551 - val_loss: 4.3797\n",
      "Epoch 20/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2654 - loss: 4.1031 - val_accuracy: 0.2573 - val_loss: 4.3655\n",
      "Epoch 21/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2658 - loss: 4.0933 - val_accuracy: 0.2556 - val_loss: 4.3558\n",
      "Epoch 22/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2669 - loss: 4.0823 - val_accuracy: 0.2589 - val_loss: 4.3365\n",
      "Epoch 23/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2678 - loss: 4.0694 - val_accuracy: 0.2587 - val_loss: 4.3179\n",
      "Epoch 24/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2684 - loss: 4.0561 - val_accuracy: 0.2600 - val_loss: 4.3006\n",
      "Epoch 25/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2697 - loss: 4.0439 - val_accuracy: 0.2587 - val_loss: 4.2959\n",
      "Epoch 26/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2695 - loss: 4.0369 - val_accuracy: 0.2607 - val_loss: 4.2746\n",
      "Epoch 27/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2709 - loss: 4.0255 - val_accuracy: 0.2637 - val_loss: 4.2655\n",
      "Epoch 28/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2716 - loss: 4.0171 - val_accuracy: 0.2636 - val_loss: 4.2460\n",
      "Epoch 29/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2719 - loss: 4.0087 - val_accuracy: 0.2623 - val_loss: 4.2388\n",
      "Epoch 30/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2721 - loss: 4.0021 - val_accuracy: 0.2658 - val_loss: 4.2182\n",
      "Epoch 31/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2739 - loss: 3.9890 - val_accuracy: 0.2641 - val_loss: 4.2159\n",
      "Epoch 32/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2735 - loss: 3.9834 - val_accuracy: 0.2666 - val_loss: 4.2017\n",
      "Epoch 33/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2750 - loss: 3.9742 - val_accuracy: 0.2647 - val_loss: 4.1909\n",
      "Epoch 34/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2753 - loss: 3.9674 - val_accuracy: 0.2668 - val_loss: 4.1873\n",
      "Epoch 35/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2757 - loss: 3.9607 - val_accuracy: 0.2668 - val_loss: 4.1723\n",
      "Epoch 36/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2750 - loss: 3.9563 - val_accuracy: 0.2659 - val_loss: 4.1600\n",
      "Epoch 37/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2768 - loss: 3.9494 - val_accuracy: 0.2665 - val_loss: 4.1532\n",
      "Epoch 38/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2769 - loss: 3.9414 - val_accuracy: 0.2686 - val_loss: 4.1499\n",
      "Epoch 39/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2772 - loss: 3.9352 - val_accuracy: 0.2685 - val_loss: 4.1391\n",
      "Epoch 40/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2779 - loss: 3.9296 - val_accuracy: 0.2700 - val_loss: 4.1237\n",
      "Epoch 41/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2780 - loss: 3.9248 - val_accuracy: 0.2710 - val_loss: 4.1245\n",
      "Epoch 42/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2790 - loss: 3.9172 - val_accuracy: 0.2691 - val_loss: 4.1015\n",
      "Epoch 43/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2793 - loss: 3.9113 - val_accuracy: 0.2716 - val_loss: 4.1004\n",
      "Epoch 44/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2797 - loss: 3.9065 - val_accuracy: 0.2703 - val_loss: 4.0970\n",
      "Epoch 45/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2802 - loss: 3.9002 - val_accuracy: 0.2698 - val_loss: 4.0876\n",
      "Epoch 46/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2803 - loss: 3.8979 - val_accuracy: 0.2722 - val_loss: 4.0773\n",
      "Epoch 47/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2811 - loss: 3.8890 - val_accuracy: 0.2730 - val_loss: 4.0625\n",
      "Epoch 48/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2817 - loss: 3.8877 - val_accuracy: 0.2711 - val_loss: 4.0559\n",
      "Epoch 49/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2818 - loss: 3.8802 - val_accuracy: 0.2742 - val_loss: 4.0490\n",
      "Epoch 50/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2815 - loss: 3.8800 - val_accuracy: 0.2733 - val_loss: 4.0452\n",
      "Epoch 51/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2822 - loss: 3.8742 - val_accuracy: 0.2742 - val_loss: 4.0407\n",
      "Epoch 52/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2830 - loss: 3.8689 - val_accuracy: 0.2745 - val_loss: 4.0394\n",
      "Epoch 53/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2834 - loss: 3.8664 - val_accuracy: 0.2729 - val_loss: 4.0360\n",
      "Epoch 54/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2839 - loss: 3.8581 - val_accuracy: 0.2765 - val_loss: 4.0234\n",
      "Epoch 55/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2841 - loss: 3.8562 - val_accuracy: 0.2765 - val_loss: 4.0116\n",
      "Epoch 56/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2848 - loss: 3.8487 - val_accuracy: 0.2770 - val_loss: 4.0079\n",
      "Epoch 57/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2848 - loss: 3.8457 - val_accuracy: 0.2762 - val_loss: 4.0056\n",
      "Epoch 58/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2849 - loss: 3.8450 - val_accuracy: 0.2771 - val_loss: 4.0037\n",
      "Epoch 59/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2854 - loss: 3.8396 - val_accuracy: 0.2762 - val_loss: 3.9918\n",
      "Epoch 60/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2858 - loss: 3.8352 - val_accuracy: 0.2766 - val_loss: 3.9904\n",
      "Epoch 61/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2857 - loss: 3.8332 - val_accuracy: 0.2759 - val_loss: 3.9868\n",
      "Epoch 62/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2860 - loss: 3.8292 - val_accuracy: 0.2806 - val_loss: 3.9768\n",
      "Epoch 63/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2870 - loss: 3.8246 - val_accuracy: 0.2780 - val_loss: 3.9758\n",
      "Epoch 64/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2867 - loss: 3.8236 - val_accuracy: 0.2807 - val_loss: 3.9701\n",
      "Epoch 65/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2865 - loss: 3.8214 - val_accuracy: 0.2786 - val_loss: 3.9712\n",
      "Epoch 66/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2867 - loss: 3.8178 - val_accuracy: 0.2811 - val_loss: 3.9585\n",
      "Epoch 67/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2880 - loss: 3.8124 - val_accuracy: 0.2827 - val_loss: 3.9501\n",
      "Epoch 68/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2879 - loss: 3.8110 - val_accuracy: 0.2797 - val_loss: 3.9527\n",
      "Epoch 69/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2878 - loss: 3.8070 - val_accuracy: 0.2844 - val_loss: 3.9419\n",
      "Epoch 70/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2881 - loss: 3.8060 - val_accuracy: 0.2847 - val_loss: 3.9356\n",
      "Epoch 71/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2880 - loss: 3.8039 - val_accuracy: 0.2832 - val_loss: 3.9437\n",
      "Epoch 72/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2890 - loss: 3.8005 - val_accuracy: 0.2835 - val_loss: 3.9295\n",
      "Epoch 73/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2890 - loss: 3.7970 - val_accuracy: 0.2843 - val_loss: 3.9228\n",
      "Epoch 74/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2894 - loss: 3.7948 - val_accuracy: 0.2838 - val_loss: 3.9247\n",
      "Epoch 75/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2898 - loss: 3.7921 - val_accuracy: 0.2864 - val_loss: 3.9115\n",
      "Epoch 76/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.2898 - loss: 3.7947 - val_accuracy: 0.2867 - val_loss: 3.9141\n",
      "Epoch 77/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2898 - loss: 3.7889 - val_accuracy: 0.2871 - val_loss: 3.9076\n",
      "Epoch 78/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2898 - loss: 3.7860 - val_accuracy: 0.2890 - val_loss: 3.9044\n",
      "Epoch 79/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2901 - loss: 3.7841 - val_accuracy: 0.2857 - val_loss: 3.9007\n",
      "Epoch 80/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2906 - loss: 3.7814 - val_accuracy: 0.2850 - val_loss: 3.9047\n",
      "Epoch 81/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2906 - loss: 3.7793 - val_accuracy: 0.2854 - val_loss: 3.8976\n",
      "Epoch 82/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2906 - loss: 3.7789 - val_accuracy: 0.2878 - val_loss: 3.8986\n",
      "Epoch 83/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.2908 - loss: 3.7753 - val_accuracy: 0.2865 - val_loss: 3.8906\n",
      "Epoch 84/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2910 - loss: 3.7717 - val_accuracy: 0.2860 - val_loss: 3.8870\n",
      "Epoch 85/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2910 - loss: 3.7720 - val_accuracy: 0.2870 - val_loss: 3.8902\n",
      "Epoch 86/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2918 - loss: 3.7678 - val_accuracy: 0.2902 - val_loss: 3.8800\n",
      "Epoch 87/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2913 - loss: 3.7678 - val_accuracy: 0.2879 - val_loss: 3.8779\n",
      "Epoch 88/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2921 - loss: 3.7627 - val_accuracy: 0.2909 - val_loss: 3.8672\n",
      "Epoch 89/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2919 - loss: 3.7642 - val_accuracy: 0.2901 - val_loss: 3.8718\n",
      "Epoch 90/90\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2922 - loss: 3.7596 - val_accuracy: 0.2880 - val_loss: 3.8684\n",
      "Restoring model weights from the end of the best epoch: 88.\n"
     ]
    }
   ],
   "source": [
    "# Duplicamos la capa LSTM\n",
    "x, y, vocab_size = build_word_sliding_windows(text)\n",
    "\n",
    "embedding_dim = 256\n",
    "rnn_units = 128\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 1024 + 512\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0bd4c9dd-63fb-48d4-8d1c-feda1f9c5279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_save_path = './word_sa_lr01-2.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db135c5c-51cc-468b-bb9b-10f19804fe57",
   "metadata": {},
   "source": [
    "Aumentamos la recurencia de la LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "30c561be-f706-4003-8b77-5e741f5fbf7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - accuracy: 0.1255 - loss: 5.8545 - val_accuracy: 0.2116 - val_loss: 5.0750\n",
      "Epoch 2/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.1991 - loss: 4.8335 - val_accuracy: 0.2189 - val_loss: 4.9089\n",
      "Epoch 3/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2192 - loss: 4.5651 - val_accuracy: 0.2256 - val_loss: 4.7865\n",
      "Epoch 4/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2373 - loss: 4.3978 - val_accuracy: 0.2316 - val_loss: 4.6946\n",
      "Epoch 5/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2517 - loss: 4.2675 - val_accuracy: 0.2388 - val_loss: 4.6000\n",
      "Epoch 6/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2617 - loss: 4.1696 - val_accuracy: 0.2417 - val_loss: 4.5509\n",
      "Epoch 7/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2675 - loss: 4.0977 - val_accuracy: 0.2487 - val_loss: 4.4725\n",
      "Epoch 8/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2722 - loss: 4.0301 - val_accuracy: 0.2541 - val_loss: 4.4330\n",
      "Epoch 9/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2758 - loss: 3.9801 - val_accuracy: 0.2558 - val_loss: 4.3871\n",
      "Epoch 10/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2784 - loss: 3.9368 - val_accuracy: 0.2519 - val_loss: 4.3583\n",
      "Epoch 11/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2813 - loss: 3.8945 - val_accuracy: 0.2595 - val_loss: 4.2968\n",
      "Epoch 12/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2849 - loss: 3.8523 - val_accuracy: 0.2593 - val_loss: 4.2781\n",
      "Epoch 13/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2877 - loss: 3.8151 - val_accuracy: 0.2601 - val_loss: 4.2425\n",
      "Epoch 14/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2901 - loss: 3.7848 - val_accuracy: 0.2595 - val_loss: 4.2152\n",
      "Epoch 15/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2926 - loss: 3.7515 - val_accuracy: 0.2653 - val_loss: 4.1841\n",
      "Epoch 16/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2952 - loss: 3.7211 - val_accuracy: 0.2660 - val_loss: 4.1402\n",
      "Epoch 17/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.2977 - loss: 3.6894 - val_accuracy: 0.2725 - val_loss: 4.1061\n",
      "Epoch 18/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3004 - loss: 3.6601 - val_accuracy: 0.2714 - val_loss: 4.0770\n",
      "Epoch 19/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3030 - loss: 3.6359 - val_accuracy: 0.2778 - val_loss: 4.0324\n",
      "Epoch 20/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3057 - loss: 3.6059 - val_accuracy: 0.2738 - val_loss: 4.0202\n",
      "Epoch 21/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3075 - loss: 3.5823 - val_accuracy: 0.2802 - val_loss: 3.9865\n",
      "Epoch 22/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3101 - loss: 3.5546 - val_accuracy: 0.2783 - val_loss: 3.9573\n",
      "Epoch 23/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3130 - loss: 3.5313 - val_accuracy: 0.2812 - val_loss: 3.9248\n",
      "Epoch 24/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3152 - loss: 3.5042 - val_accuracy: 0.2842 - val_loss: 3.8992\n",
      "Epoch 25/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3180 - loss: 3.4803 - val_accuracy: 0.2837 - val_loss: 3.8747\n",
      "Epoch 26/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3198 - loss: 3.4605 - val_accuracy: 0.2885 - val_loss: 3.8414\n",
      "Epoch 27/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3225 - loss: 3.4375 - val_accuracy: 0.2915 - val_loss: 3.8130\n",
      "Epoch 28/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3254 - loss: 3.4124 - val_accuracy: 0.2929 - val_loss: 3.7884\n",
      "Epoch 29/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3283 - loss: 3.3843 - val_accuracy: 0.2924 - val_loss: 3.7667\n",
      "Epoch 30/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3298 - loss: 3.3733 - val_accuracy: 0.2965 - val_loss: 3.7399\n",
      "Epoch 31/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3325 - loss: 3.3494 - val_accuracy: 0.3001 - val_loss: 3.7080\n",
      "Epoch 32/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3355 - loss: 3.3275 - val_accuracy: 0.2992 - val_loss: 3.6937\n",
      "Epoch 33/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3376 - loss: 3.3066 - val_accuracy: 0.3036 - val_loss: 3.6573\n",
      "Epoch 34/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3406 - loss: 3.2876 - val_accuracy: 0.3086 - val_loss: 3.6379\n",
      "Epoch 35/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3426 - loss: 3.2680 - val_accuracy: 0.3046 - val_loss: 3.6432\n",
      "Epoch 36/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3441 - loss: 3.2559 - val_accuracy: 0.3082 - val_loss: 3.6032\n",
      "Epoch 37/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3473 - loss: 3.2332 - val_accuracy: 0.3179 - val_loss: 3.5777\n",
      "Epoch 38/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3495 - loss: 3.2153 - val_accuracy: 0.3151 - val_loss: 3.5732\n",
      "Epoch 39/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3510 - loss: 3.2030 - val_accuracy: 0.3195 - val_loss: 3.5337\n",
      "Epoch 40/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3541 - loss: 3.1839 - val_accuracy: 0.3166 - val_loss: 3.5279\n",
      "Epoch 41/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3560 - loss: 3.1674 - val_accuracy: 0.3221 - val_loss: 3.5020\n",
      "Epoch 42/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3579 - loss: 3.1509 - val_accuracy: 0.3234 - val_loss: 3.4785\n",
      "Epoch 43/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3603 - loss: 3.1356 - val_accuracy: 0.3274 - val_loss: 3.4600\n",
      "Epoch 44/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3622 - loss: 3.1213 - val_accuracy: 0.3328 - val_loss: 3.4414\n",
      "Epoch 45/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3642 - loss: 3.1074 - val_accuracy: 0.3286 - val_loss: 3.4285\n",
      "Epoch 46/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3663 - loss: 3.0932 - val_accuracy: 0.3300 - val_loss: 3.4151\n",
      "Epoch 47/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3671 - loss: 3.0814 - val_accuracy: 0.3381 - val_loss: 3.3919\n",
      "Epoch 48/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3695 - loss: 3.0655 - val_accuracy: 0.3381 - val_loss: 3.3808\n",
      "Epoch 49/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3715 - loss: 3.0533 - val_accuracy: 0.3400 - val_loss: 3.3709\n",
      "Epoch 50/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3731 - loss: 3.0428 - val_accuracy: 0.3439 - val_loss: 3.3529\n",
      "Epoch 51/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3746 - loss: 3.0305 - val_accuracy: 0.3469 - val_loss: 3.3378\n",
      "Epoch 52/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.3763 - loss: 3.0196 - val_accuracy: 0.3451 - val_loss: 3.3208\n",
      "Epoch 53/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3783 - loss: 3.0059 - val_accuracy: 0.3525 - val_loss: 3.2997\n",
      "Epoch 54/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3798 - loss: 2.9942 - val_accuracy: 0.3498 - val_loss: 3.2889\n",
      "Epoch 55/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3817 - loss: 2.9818 - val_accuracy: 0.3547 - val_loss: 3.2768\n",
      "Epoch 56/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3822 - loss: 2.9767 - val_accuracy: 0.3604 - val_loss: 3.2610\n",
      "Epoch 57/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3843 - loss: 2.9660 - val_accuracy: 0.3587 - val_loss: 3.2505\n",
      "Epoch 58/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3860 - loss: 2.9535 - val_accuracy: 0.3541 - val_loss: 3.2378\n",
      "Epoch 59/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3867 - loss: 2.9451 - val_accuracy: 0.3566 - val_loss: 3.2202\n",
      "Epoch 60/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3885 - loss: 2.9361 - val_accuracy: 0.3575 - val_loss: 3.2272\n",
      "Epoch 61/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3893 - loss: 2.9326 - val_accuracy: 0.3642 - val_loss: 3.2047\n",
      "Epoch 62/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3910 - loss: 2.9209 - val_accuracy: 0.3655 - val_loss: 3.1941\n",
      "Epoch 63/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3934 - loss: 2.9064 - val_accuracy: 0.3678 - val_loss: 3.1838\n",
      "Epoch 64/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.3932 - loss: 2.9059 - val_accuracy: 0.3632 - val_loss: 3.1806\n",
      "Epoch 65/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3941 - loss: 2.8993 - val_accuracy: 0.3668 - val_loss: 3.1662\n",
      "Epoch 66/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3955 - loss: 2.8914 - val_accuracy: 0.3677 - val_loss: 3.1530\n",
      "Epoch 67/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3970 - loss: 2.8789 - val_accuracy: 0.3720 - val_loss: 3.1423\n",
      "Epoch 68/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3990 - loss: 2.8688 - val_accuracy: 0.3722 - val_loss: 3.1341\n",
      "Epoch 69/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.3992 - loss: 2.8666 - val_accuracy: 0.3730 - val_loss: 3.1325\n",
      "Epoch 70/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.3998 - loss: 2.8601 - val_accuracy: 0.3755 - val_loss: 3.1135\n",
      "Epoch 71/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.4015 - loss: 2.8481 - val_accuracy: 0.3747 - val_loss: 3.1050\n",
      "Epoch 72/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4016 - loss: 2.8468 - val_accuracy: 0.3769 - val_loss: 3.0966\n",
      "Epoch 73/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.4033 - loss: 2.8390 - val_accuracy: 0.3770 - val_loss: 3.0922\n",
      "Epoch 74/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4037 - loss: 2.8336 - val_accuracy: 0.3779 - val_loss: 3.0829\n",
      "Epoch 75/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.4036 - loss: 2.8363 - val_accuracy: 0.3809 - val_loss: 3.0720\n",
      "Epoch 76/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4067 - loss: 2.8171 - val_accuracy: 0.3819 - val_loss: 3.0684\n",
      "Epoch 77/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4071 - loss: 2.8122 - val_accuracy: 0.3824 - val_loss: 3.0674\n",
      "Epoch 78/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4061 - loss: 2.8148 - val_accuracy: 0.3833 - val_loss: 3.0597\n",
      "Epoch 79/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4092 - loss: 2.8008 - val_accuracy: 0.3870 - val_loss: 3.0417\n",
      "Epoch 80/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4101 - loss: 2.7947 - val_accuracy: 0.3877 - val_loss: 3.0458\n",
      "Epoch 81/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4105 - loss: 2.7899 - val_accuracy: 0.3887 - val_loss: 3.0381\n",
      "Epoch 82/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4090 - loss: 2.7935 - val_accuracy: 0.3888 - val_loss: 3.0356\n",
      "Epoch 83/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4122 - loss: 2.7824 - val_accuracy: 0.3895 - val_loss: 3.0298\n",
      "Epoch 84/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4104 - loss: 2.7851 - val_accuracy: 0.3918 - val_loss: 3.0142\n",
      "Epoch 85/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.4134 - loss: 2.7714 - val_accuracy: 0.3929 - val_loss: 3.0013\n",
      "Epoch 86/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.4138 - loss: 2.7702 - val_accuracy: 0.3938 - val_loss: 2.9900\n",
      "Epoch 87/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.4146 - loss: 2.7639 - val_accuracy: 0.3873 - val_loss: 3.0002\n",
      "Epoch 88/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.4144 - loss: 2.7642 - val_accuracy: 0.3898 - val_loss: 2.9973\n",
      "Epoch 89/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.4154 - loss: 2.7570 - val_accuracy: 0.3961 - val_loss: 2.9814\n",
      "Epoch 90/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - accuracy: 0.4149 - loss: 2.7558 - val_accuracy: 0.3956 - val_loss: 2.9813\n",
      "Restoring model weights from the end of the best epoch: 90.\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text)\n",
    "\n",
    "embedding_dim = 256\n",
    "rnn_units = 256\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 2048\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef59d3a3-04ae-4d45-bf55-324e1bc1f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_sa_lr01-3.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603318d-44c1-4bb8-8135-c0574324585d",
   "metadata": {},
   "source": [
    "Aumentamos la dimencion del embedding y la recurrencia de la LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e8fc42d-f7b8-4bdc-9cdb-ca677aee48c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5001</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565,513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_32 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m2,560,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_42 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5001\u001b[0m)           │     \u001b[38;5;34m2,565,513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,225,225</span> (27.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,225,225\u001b[0m (27.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,225,225</span> (27.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,225,225\u001b[0m (27.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 73ms/step - accuracy: 0.1456 - loss: 5.5918 - val_accuracy: 0.2181 - val_loss: 4.9432\n",
      "Epoch 2/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 46ms/step - accuracy: 0.2169 - loss: 4.5969 - val_accuracy: 0.2293 - val_loss: 4.7402\n",
      "Epoch 3/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.2444 - loss: 4.3236 - val_accuracy: 0.2409 - val_loss: 4.5974\n",
      "Epoch 4/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.2619 - loss: 4.1492 - val_accuracy: 0.2413 - val_loss: 4.4831\n",
      "Epoch 5/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.2704 - loss: 4.0253 - val_accuracy: 0.2488 - val_loss: 4.3725\n",
      "Epoch 6/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.2776 - loss: 3.9257 - val_accuracy: 0.2493 - val_loss: 4.3029\n",
      "Epoch 7/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.2832 - loss: 3.8422 - val_accuracy: 0.2547 - val_loss: 4.2294\n",
      "Epoch 8/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.2887 - loss: 3.7659 - val_accuracy: 0.2623 - val_loss: 4.1400\n",
      "Epoch 9/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.2940 - loss: 3.6934 - val_accuracy: 0.2626 - val_loss: 4.0601\n",
      "Epoch 10/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.2997 - loss: 3.6245 - val_accuracy: 0.2714 - val_loss: 3.9962\n",
      "Epoch 11/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3053 - loss: 3.5596 - val_accuracy: 0.2759 - val_loss: 3.9165\n",
      "Epoch 12/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3115 - loss: 3.4960 - val_accuracy: 0.2799 - val_loss: 3.8641\n",
      "Epoch 13/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3172 - loss: 3.4341 - val_accuracy: 0.2840 - val_loss: 3.7806\n",
      "Epoch 14/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3240 - loss: 3.3713 - val_accuracy: 0.2916 - val_loss: 3.7135\n",
      "Epoch 15/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3306 - loss: 3.3115 - val_accuracy: 0.3003 - val_loss: 3.6525\n",
      "Epoch 16/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3372 - loss: 3.2538 - val_accuracy: 0.3055 - val_loss: 3.5740\n",
      "Epoch 17/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3447 - loss: 3.1919 - val_accuracy: 0.3123 - val_loss: 3.5108\n",
      "Epoch 18/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3527 - loss: 3.1314 - val_accuracy: 0.3213 - val_loss: 3.4424\n",
      "Epoch 19/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3595 - loss: 3.0784 - val_accuracy: 0.3262 - val_loss: 3.3772\n",
      "Epoch 20/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3678 - loss: 3.0206 - val_accuracy: 0.3347 - val_loss: 3.3213\n",
      "Epoch 21/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3755 - loss: 2.9671 - val_accuracy: 0.3439 - val_loss: 3.2512\n",
      "Epoch 22/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3845 - loss: 2.9108 - val_accuracy: 0.3533 - val_loss: 3.1769\n",
      "Epoch 23/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3915 - loss: 2.8619 - val_accuracy: 0.3587 - val_loss: 3.1255\n",
      "Epoch 24/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.3997 - loss: 2.8100 - val_accuracy: 0.3671 - val_loss: 3.0754\n",
      "Epoch 25/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.4073 - loss: 2.7638 - val_accuracy: 0.3730 - val_loss: 3.0158\n",
      "Epoch 26/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.4159 - loss: 2.7144 - val_accuracy: 0.3903 - val_loss: 2.9433\n",
      "Epoch 27/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4241 - loss: 2.6650 - val_accuracy: 0.3963 - val_loss: 2.9035\n",
      "Epoch 28/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 47ms/step - accuracy: 0.4314 - loss: 2.6223 - val_accuracy: 0.4021 - val_loss: 2.8479\n",
      "Epoch 29/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4395 - loss: 2.5781 - val_accuracy: 0.4134 - val_loss: 2.7923\n",
      "Epoch 30/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4470 - loss: 2.5357 - val_accuracy: 0.4205 - val_loss: 2.7416\n",
      "Epoch 31/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4541 - loss: 2.4947 - val_accuracy: 0.4269 - val_loss: 2.7077\n",
      "Epoch 32/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4601 - loss: 2.4608 - val_accuracy: 0.4417 - val_loss: 2.6495\n",
      "Epoch 33/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4689 - loss: 2.4140 - val_accuracy: 0.4444 - val_loss: 2.6179\n",
      "Epoch 34/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4733 - loss: 2.3882 - val_accuracy: 0.4568 - val_loss: 2.5544\n",
      "Epoch 35/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4817 - loss: 2.3457 - val_accuracy: 0.4637 - val_loss: 2.5181\n",
      "Epoch 36/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4870 - loss: 2.3163 - val_accuracy: 0.4683 - val_loss: 2.4855\n",
      "Epoch 37/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4928 - loss: 2.2833 - val_accuracy: 0.4730 - val_loss: 2.4411\n",
      "Epoch 38/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.4987 - loss: 2.2534 - val_accuracy: 0.4853 - val_loss: 2.4044\n",
      "Epoch 39/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5049 - loss: 2.2227 - val_accuracy: 0.4902 - val_loss: 2.3705\n",
      "Epoch 40/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5105 - loss: 2.1917 - val_accuracy: 0.4986 - val_loss: 2.3412\n",
      "Epoch 41/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5161 - loss: 2.1631 - val_accuracy: 0.5009 - val_loss: 2.3142\n",
      "Epoch 42/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5216 - loss: 2.1352 - val_accuracy: 0.5104 - val_loss: 2.2636\n",
      "Epoch 43/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5272 - loss: 2.1084 - val_accuracy: 0.5144 - val_loss: 2.2394\n",
      "Epoch 44/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5323 - loss: 2.0821 - val_accuracy: 0.5180 - val_loss: 2.2186\n",
      "Epoch 45/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5369 - loss: 2.0572 - val_accuracy: 0.5228 - val_loss: 2.1847\n",
      "Epoch 46/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5399 - loss: 2.0404 - val_accuracy: 0.5259 - val_loss: 2.1659\n",
      "Epoch 47/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5430 - loss: 2.0234 - val_accuracy: 0.5346 - val_loss: 2.1297\n",
      "Epoch 48/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5481 - loss: 1.9996 - val_accuracy: 0.5357 - val_loss: 2.1096\n",
      "Epoch 49/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5532 - loss: 1.9744 - val_accuracy: 0.5418 - val_loss: 2.0758\n",
      "Epoch 50/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5570 - loss: 1.9557 - val_accuracy: 0.5537 - val_loss: 2.0610\n",
      "Epoch 51/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5590 - loss: 1.9427 - val_accuracy: 0.5540 - val_loss: 2.0389\n",
      "Epoch 52/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5646 - loss: 1.9164 - val_accuracy: 0.5574 - val_loss: 2.0205\n",
      "Epoch 53/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5662 - loss: 1.9051 - val_accuracy: 0.5558 - val_loss: 2.0141\n",
      "Epoch 54/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5683 - loss: 1.8921 - val_accuracy: 0.5644 - val_loss: 1.9820\n",
      "Epoch 55/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5760 - loss: 1.8587 - val_accuracy: 0.5656 - val_loss: 1.9625\n",
      "Epoch 56/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5783 - loss: 1.8467 - val_accuracy: 0.5781 - val_loss: 1.9335\n",
      "Epoch 57/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5814 - loss: 1.8316 - val_accuracy: 0.5674 - val_loss: 1.9423\n",
      "Epoch 58/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5751 - loss: 1.8514 - val_accuracy: 0.5827 - val_loss: 1.8974\n",
      "Epoch 59/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5862 - loss: 1.8064 - val_accuracy: 0.5787 - val_loss: 1.9047\n",
      "Epoch 60/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5828 - loss: 1.8147 - val_accuracy: 0.5834 - val_loss: 1.8747\n",
      "Epoch 61/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5889 - loss: 1.7884 - val_accuracy: 0.5822 - val_loss: 1.8746\n",
      "Epoch 62/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5923 - loss: 1.7719 - val_accuracy: 0.5878 - val_loss: 1.8408\n",
      "Epoch 63/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5963 - loss: 1.7539 - val_accuracy: 0.5887 - val_loss: 1.8263\n",
      "Epoch 64/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5959 - loss: 1.7518 - val_accuracy: 0.5926 - val_loss: 1.8209\n",
      "Epoch 65/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.5964 - loss: 1.7471 - val_accuracy: 0.5967 - val_loss: 1.8085\n",
      "Epoch 66/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.5999 - loss: 1.7293 - val_accuracy: 0.5976 - val_loss: 1.7990\n",
      "Epoch 67/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.6038 - loss: 1.7130 - val_accuracy: 0.5999 - val_loss: 1.7874\n",
      "Epoch 68/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.6053 - loss: 1.7034 - val_accuracy: 0.5985 - val_loss: 1.7764\n",
      "Epoch 69/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6039 - loss: 1.7054 - val_accuracy: 0.6034 - val_loss: 1.7702\n",
      "Epoch 70/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 47ms/step - accuracy: 0.6065 - loss: 1.6938 - val_accuracy: 0.6038 - val_loss: 1.7619\n",
      "Epoch 71/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6083 - loss: 1.6841 - val_accuracy: 0.6084 - val_loss: 1.7401\n",
      "Epoch 72/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6149 - loss: 1.6563 - val_accuracy: 0.6085 - val_loss: 1.7328\n",
      "Epoch 73/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6114 - loss: 1.6673 - val_accuracy: 0.6118 - val_loss: 1.7289\n",
      "Epoch 74/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6127 - loss: 1.6578 - val_accuracy: 0.6098 - val_loss: 1.7193\n",
      "Epoch 75/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 49ms/step - accuracy: 0.6105 - loss: 1.6635 - val_accuracy: 0.6159 - val_loss: 1.6963\n",
      "Epoch 76/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6189 - loss: 1.6337 - val_accuracy: 0.6118 - val_loss: 1.6960\n",
      "Epoch 77/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 49ms/step - accuracy: 0.6173 - loss: 1.6364 - val_accuracy: 0.6172 - val_loss: 1.6813\n",
      "Epoch 78/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6231 - loss: 1.6113 - val_accuracy: 0.6195 - val_loss: 1.6769\n",
      "Epoch 79/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6208 - loss: 1.6169 - val_accuracy: 0.6242 - val_loss: 1.6672\n",
      "Epoch 80/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6198 - loss: 1.6180 - val_accuracy: 0.6205 - val_loss: 1.6587\n",
      "Epoch 81/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6211 - loss: 1.6119 - val_accuracy: 0.6235 - val_loss: 1.6641\n",
      "Epoch 82/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6184 - loss: 1.6180 - val_accuracy: 0.6301 - val_loss: 1.6425\n",
      "Epoch 83/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6256 - loss: 1.5928 - val_accuracy: 0.6282 - val_loss: 1.6509\n",
      "Epoch 84/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6254 - loss: 1.5897 - val_accuracy: 0.6237 - val_loss: 1.6513\n",
      "Epoch 85/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6237 - loss: 1.5938 - val_accuracy: 0.6300 - val_loss: 1.6259\n",
      "Epoch 86/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6246 - loss: 1.5894 - val_accuracy: 0.6311 - val_loss: 1.6183\n",
      "Epoch 87/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6286 - loss: 1.5708 - val_accuracy: 0.6318 - val_loss: 1.6167\n",
      "Epoch 88/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6304 - loss: 1.5628 - val_accuracy: 0.6336 - val_loss: 1.5994\n",
      "Epoch 89/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6347 - loss: 1.5455 - val_accuracy: 0.6359 - val_loss: 1.5978\n",
      "Epoch 90/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.6334 - loss: 1.5476 - val_accuracy: 0.6321 - val_loss: 1.5988\n",
      "Restoring model weights from the end of the best epoch: 89.\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text)\n",
    "\n",
    "embedding_dim = 512\n",
    "rnn_units = 512\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 2048\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "daf36a69-a5c1-4bdd-9273-1e9db8325f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_sa_lr01-4.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ea8f4-4a28-4175-bff2-2d8f821554fe",
   "metadata": {},
   "source": [
    "Impresionante mejora del modelo simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4306994-be14-4153-81e4-30cd1dd2fdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature 0.5:\n",
      "It was a dark and stormy night aspects son banquet represented hopes defects flows companions reproach compared gymnastic ludicrous family is’ dwells applicable plenty sounding abstraction choose\n",
      "\n",
      "Temperature 1.0:\n",
      "It was a dark and stormy night peace service daily distinctly speeches carrying areopagus flesh thin becomes incurable selected notifies προς 2001 described employee εν belongs direction\n",
      "\n",
      "Temperature 1.2 (different seed):\n",
      "The king declared ζώον continuous enemy ridicule need science fighting harmless description fields επιστήμη οποία sufficiently sources 8 devoid existing accuracy injustice keen\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a dark and stormy night\"\n",
    "generated_output_temp_0_5 = generate_text(model, start_string=seed_text, num_generate=20, temperature=0.5)\n",
    "# To see the output, you would need to print it:\n",
    "print(f\"\\nTemperature 0.5:\\n{generated_output_temp_0_5}\")\n",
    "\n",
    "generated_output_temp_1_0 = generate_text(model, start_string=seed_text, num_generate=20, temperature=1.0)\n",
    "print(f\"\\nTemperature 1.0:\\n{generated_output_temp_1_0}\")\n",
    "\n",
    "generated_output_temp_1_5 = generate_text(model, start_string=\"The king declared\", num_generate=20, temperature=1.2)\n",
    "print(f\"\\nTemperature 1.2 (different seed):\\n{generated_output_temp_1_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c408e-17f2-4c4a-9423-4e26caff0b6e",
   "metadata": {},
   "source": [
    "Si bien el accuracy mejoro mucho, las oraciones siguen sin tener sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed83c8-3557-4ca7-a9e9-4c0e3d65b687",
   "metadata": {},
   "source": [
    "# Arquitectura vista en clase\n",
    "\n",
    "Experimentamos con la arquitectura vista en clae pero aumentando la dimension del embedding y la cantidad de rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15bf3dce-1e3d-485f-bb1a-7274eb48433c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">244,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5002</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">165,066</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_24 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m1,280,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m244,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m55,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5002\u001b[0m)           │       \u001b[38;5;34m165,066\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,746,642</span> (6.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,746,642\u001b[0m (6.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,746,642</span> (6.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,746,642\u001b[0m (6.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "embedding_dim = 256 \n",
    "rnn_units = 150 \n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(vocab_size+1, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 64 \n",
    "batch_size = 1024\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dcb6d415-4618-4558-a912-e7ba6770a15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.1133 - loss: 5.8494 - val_accuracy: 0.2086 - val_loss: 5.0828\n",
      "Epoch 2/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 11ms/step - accuracy: 0.2001 - loss: 4.8086 - val_accuracy: 0.2229 - val_loss: 4.9127\n",
      "Epoch 3/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2246 - loss: 4.5660 - val_accuracy: 0.2298 - val_loss: 4.8452\n",
      "Epoch 4/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2407 - loss: 4.4292 - val_accuracy: 0.2375 - val_loss: 4.7646\n",
      "Epoch 5/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2495 - loss: 4.3534 - val_accuracy: 0.2381 - val_loss: 4.7174\n",
      "Epoch 6/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.2542 - loss: 4.2932 - val_accuracy: 0.2427 - val_loss: 4.6541\n",
      "Epoch 7/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 12ms/step - accuracy: 0.2572 - loss: 4.2528 - val_accuracy: 0.2462 - val_loss: 4.6054\n",
      "Epoch 8/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 12ms/step - accuracy: 0.2607 - loss: 4.2152 - val_accuracy: 0.2472 - val_loss: 4.5830\n",
      "Epoch 9/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.2633 - loss: 4.1820 - val_accuracy: 0.2477 - val_loss: 4.5353\n",
      "Epoch 10/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2653 - loss: 4.1585 - val_accuracy: 0.2543 - val_loss: 4.5122\n",
      "Epoch 11/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2667 - loss: 4.1353 - val_accuracy: 0.2525 - val_loss: 4.4915\n",
      "Epoch 12/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2683 - loss: 4.1169 - val_accuracy: 0.2536 - val_loss: 4.4645\n",
      "Epoch 13/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2704 - loss: 4.0955 - val_accuracy: 0.2555 - val_loss: 4.4503\n",
      "Epoch 14/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2714 - loss: 4.0785 - val_accuracy: 0.2541 - val_loss: 4.4348\n",
      "Epoch 15/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2727 - loss: 4.0643 - val_accuracy: 0.2598 - val_loss: 4.4109\n",
      "Epoch 16/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2742 - loss: 4.0477 - val_accuracy: 0.2590 - val_loss: 4.3952\n",
      "Epoch 17/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2749 - loss: 4.0371 - val_accuracy: 0.2598 - val_loss: 4.3770\n",
      "Epoch 18/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2760 - loss: 4.0216 - val_accuracy: 0.2626 - val_loss: 4.3586\n",
      "Epoch 19/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2769 - loss: 4.0115 - val_accuracy: 0.2651 - val_loss: 4.3527\n",
      "Epoch 20/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2785 - loss: 3.9979 - val_accuracy: 0.2620 - val_loss: 4.3347\n",
      "Epoch 21/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2783 - loss: 3.9906 - val_accuracy: 0.2669 - val_loss: 4.3089\n",
      "Epoch 22/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2800 - loss: 3.9778 - val_accuracy: 0.2651 - val_loss: 4.3136\n",
      "Epoch 23/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2807 - loss: 3.9701 - val_accuracy: 0.2687 - val_loss: 4.2940\n",
      "Epoch 24/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2813 - loss: 3.9605 - val_accuracy: 0.2687 - val_loss: 4.2689\n",
      "Epoch 25/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2823 - loss: 3.9491 - val_accuracy: 0.2725 - val_loss: 4.2695\n",
      "Epoch 26/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2837 - loss: 3.9415 - val_accuracy: 0.2702 - val_loss: 4.2612\n",
      "Epoch 27/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2840 - loss: 3.9360 - val_accuracy: 0.2734 - val_loss: 4.2482\n",
      "Epoch 28/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2841 - loss: 3.9298 - val_accuracy: 0.2743 - val_loss: 4.2372\n",
      "Epoch 29/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2849 - loss: 3.9216 - val_accuracy: 0.2740 - val_loss: 4.2272\n",
      "Epoch 30/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2858 - loss: 3.9148 - val_accuracy: 0.2728 - val_loss: 4.2237\n",
      "Epoch 31/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2859 - loss: 3.9095 - val_accuracy: 0.2733 - val_loss: 4.2198\n",
      "Epoch 32/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2867 - loss: 3.9023 - val_accuracy: 0.2771 - val_loss: 4.2108\n",
      "Epoch 33/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2866 - loss: 3.9006 - val_accuracy: 0.2737 - val_loss: 4.2100\n",
      "Epoch 34/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2874 - loss: 3.8926 - val_accuracy: 0.2762 - val_loss: 4.1968\n",
      "Epoch 35/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2878 - loss: 3.8870 - val_accuracy: 0.2796 - val_loss: 4.1830\n",
      "Epoch 36/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2882 - loss: 3.8831 - val_accuracy: 0.2744 - val_loss: 4.1865\n",
      "Epoch 37/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2886 - loss: 3.8792 - val_accuracy: 0.2801 - val_loss: 4.1648\n",
      "Epoch 38/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2891 - loss: 3.8749 - val_accuracy: 0.2794 - val_loss: 4.1695\n",
      "Epoch 39/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2895 - loss: 3.8672 - val_accuracy: 0.2798 - val_loss: 4.1702\n",
      "Epoch 40/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2895 - loss: 3.8648 - val_accuracy: 0.2785 - val_loss: 4.1687\n",
      "Epoch 41/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2899 - loss: 3.8617 - val_accuracy: 0.2769 - val_loss: 4.1721\n",
      "Epoch 42/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2907 - loss: 3.8576 - val_accuracy: 0.2790 - val_loss: 4.1587\n",
      "Epoch 43/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2904 - loss: 3.8567 - val_accuracy: 0.2793 - val_loss: 4.1623\n",
      "Epoch 44/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2910 - loss: 3.8509 - val_accuracy: 0.2802 - val_loss: 4.1512\n",
      "Epoch 45/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2906 - loss: 3.8495 - val_accuracy: 0.2786 - val_loss: 4.1514\n",
      "Epoch 46/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2916 - loss: 3.8446 - val_accuracy: 0.2796 - val_loss: 4.1366\n",
      "Epoch 47/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2914 - loss: 3.8453 - val_accuracy: 0.2812 - val_loss: 4.1350\n",
      "Epoch 48/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2918 - loss: 3.8379 - val_accuracy: 0.2830 - val_loss: 4.1274\n",
      "Epoch 49/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2923 - loss: 3.8380 - val_accuracy: 0.2812 - val_loss: 4.1312\n",
      "Epoch 50/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2924 - loss: 3.8354 - val_accuracy: 0.2796 - val_loss: 4.1352\n",
      "Epoch 51/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2933 - loss: 3.8353 - val_accuracy: 0.2867 - val_loss: 4.1153\n",
      "Epoch 52/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2923 - loss: 3.8326 - val_accuracy: 0.2828 - val_loss: 4.1200\n",
      "Epoch 53/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2929 - loss: 3.8294 - val_accuracy: 0.2850 - val_loss: 4.1141\n",
      "Epoch 54/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2928 - loss: 3.8280 - val_accuracy: 0.2826 - val_loss: 4.1277\n",
      "Epoch 55/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.2933 - loss: 3.8280 - val_accuracy: 0.2799 - val_loss: 4.1226\n",
      "Epoch 56/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2932 - loss: 3.8272 - val_accuracy: 0.2809 - val_loss: 4.1144\n",
      "Epoch 57/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2928 - loss: 3.8263 - val_accuracy: 0.2814 - val_loss: 4.1209\n",
      "Epoch 58/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2929 - loss: 3.8238 - val_accuracy: 0.2866 - val_loss: 4.1115\n",
      "Epoch 59/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2939 - loss: 3.8175 - val_accuracy: 0.2832 - val_loss: 4.1130\n",
      "Epoch 60/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2934 - loss: 3.8187 - val_accuracy: 0.2837 - val_loss: 4.1068\n",
      "Epoch 61/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2937 - loss: 3.8187 - val_accuracy: 0.2824 - val_loss: 4.1105\n",
      "Epoch 62/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2937 - loss: 3.8170 - val_accuracy: 0.2815 - val_loss: 4.1039\n",
      "Epoch 63/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2937 - loss: 3.8159 - val_accuracy: 0.2853 - val_loss: 4.0983\n",
      "Epoch 64/64\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.2939 - loss: 3.8129 - val_accuracy: 0.2857 - val_loss: 4.1092\n",
      "Restoring model weights from the end of the best epoch: 63.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "model_save_path = './word_arch_class_lr01.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b026ab-acd7-4c8b-9dcd-95ba9e1fdb63",
   "metadata": {},
   "source": [
    "Aumentamos la recurencia y la dimension del embedding y vemos si mejora el accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "04eceea4-dc8a-4d3d-91d6-5a4d9f256ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5002</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">165,066</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_30 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m2,560,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_40 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_41 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m147,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5002\u001b[0m)           │       \u001b[38;5;34m165,066\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,974,570</span> (18.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,974,570\u001b[0m (18.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,974,570</span> (18.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,974,570\u001b[0m (18.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aumentamos embedding y rnn\n",
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "embedding_dim = 512 \n",
    "rnn_units = 512\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(rnn_units),\n",
    "    layers.Dense(vocab_size, activation='relu'),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90 \n",
    "batch_size = 2048\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "883c0331-d61d-47b7-88a6-db88892dcce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 83ms/step - accuracy: 0.0777 - loss: 6.2687 - val_accuracy: 0.1477 - val_loss: 5.7064\n",
      "Epoch 2/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 84ms/step - accuracy: 0.1362 - loss: 5.5859 - val_accuracy: 0.2088 - val_loss: 5.1244\n",
      "Epoch 3/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 85ms/step - accuracy: 0.1948 - loss: 4.8991 - val_accuracy: 0.2170 - val_loss: 4.9763\n",
      "Epoch 4/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 85ms/step - accuracy: 0.2146 - loss: 4.6718 - val_accuracy: 0.2208 - val_loss: 4.8902\n",
      "Epoch 5/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 85ms/step - accuracy: 0.2327 - loss: 4.5187 - val_accuracy: 0.2362 - val_loss: 4.8142\n",
      "Epoch 6/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 85ms/step - accuracy: 0.2473 - loss: 4.4102 - val_accuracy: 0.2398 - val_loss: 4.7530\n",
      "Epoch 7/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2551 - loss: 4.3318 - val_accuracy: 0.2416 - val_loss: 4.6959\n",
      "Epoch 8/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2605 - loss: 4.2745 - val_accuracy: 0.2438 - val_loss: 4.6557\n",
      "Epoch 9/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2646 - loss: 4.2244 - val_accuracy: 0.2477 - val_loss: 4.6008\n",
      "Epoch 10/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 86ms/step - accuracy: 0.2694 - loss: 4.1746 - val_accuracy: 0.2531 - val_loss: 4.5630\n",
      "Epoch 11/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2727 - loss: 4.1347 - val_accuracy: 0.2566 - val_loss: 4.5291\n",
      "Epoch 12/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2759 - loss: 4.0943 - val_accuracy: 0.2592 - val_loss: 4.4727\n",
      "Epoch 13/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2789 - loss: 4.0575 - val_accuracy: 0.2643 - val_loss: 4.4321\n",
      "Epoch 14/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2824 - loss: 4.0211 - val_accuracy: 0.2641 - val_loss: 4.3853\n",
      "Epoch 15/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2859 - loss: 3.9834 - val_accuracy: 0.2717 - val_loss: 4.3567\n",
      "Epoch 16/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2892 - loss: 3.9496 - val_accuracy: 0.2726 - val_loss: 4.3116\n",
      "Epoch 17/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2915 - loss: 3.9196 - val_accuracy: 0.2757 - val_loss: 4.2559\n",
      "Epoch 18/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2948 - loss: 3.8862 - val_accuracy: 0.2774 - val_loss: 4.2313\n",
      "Epoch 19/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.2979 - loss: 3.8547 - val_accuracy: 0.2815 - val_loss: 4.1827\n",
      "Epoch 20/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 86ms/step - accuracy: 0.3009 - loss: 3.8243 - val_accuracy: 0.2856 - val_loss: 4.1652\n",
      "Epoch 21/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.3032 - loss: 3.7971 - val_accuracy: 0.2879 - val_loss: 4.1186\n",
      "Epoch 22/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 86ms/step - accuracy: 0.3070 - loss: 3.7658 - val_accuracy: 0.2921 - val_loss: 4.0778\n",
      "Epoch 23/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.3101 - loss: 3.7352 - val_accuracy: 0.2913 - val_loss: 4.0572\n",
      "Epoch 24/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - accuracy: 0.3133 - loss: 3.7053 - val_accuracy: 0.2968 - val_loss: 4.0342\n",
      "Epoch 25/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 86ms/step - accuracy: 0.3140 - loss: 3.6946 - val_accuracy: 0.3019 - val_loss: 3.9834\n",
      "Epoch 26/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 86ms/step - accuracy: 0.3186 - loss: 3.6543 - val_accuracy: 0.2982 - val_loss: 3.9585\n",
      "Epoch 27/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3207 - loss: 3.6366 - val_accuracy: 0.3035 - val_loss: 3.9367\n",
      "Epoch 28/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3233 - loss: 3.6101 - val_accuracy: 0.3069 - val_loss: 3.8940\n",
      "Epoch 29/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3260 - loss: 3.5827 - val_accuracy: 0.3144 - val_loss: 3.8537\n",
      "Epoch 30/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3285 - loss: 3.5658 - val_accuracy: 0.3169 - val_loss: 3.8306\n",
      "Epoch 31/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3304 - loss: 3.5519 - val_accuracy: 0.3195 - val_loss: 3.8100\n",
      "Epoch 32/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3333 - loss: 3.5236 - val_accuracy: 0.3244 - val_loss: 3.7765\n",
      "Epoch 33/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3359 - loss: 3.5012 - val_accuracy: 0.3276 - val_loss: 3.7594\n",
      "Epoch 34/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3374 - loss: 3.4873 - val_accuracy: 0.3301 - val_loss: 3.7270\n",
      "Epoch 35/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3393 - loss: 3.4694 - val_accuracy: 0.3274 - val_loss: 3.7214\n",
      "Epoch 36/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3413 - loss: 3.4529 - val_accuracy: 0.3332 - val_loss: 3.7053\n",
      "Epoch 37/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3424 - loss: 3.4424 - val_accuracy: 0.3364 - val_loss: 3.6549\n",
      "Epoch 38/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3443 - loss: 3.4264 - val_accuracy: 0.3340 - val_loss: 3.6560\n",
      "Epoch 39/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3468 - loss: 3.4043 - val_accuracy: 0.3441 - val_loss: 3.6169\n",
      "Epoch 40/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3489 - loss: 3.3883 - val_accuracy: 0.3395 - val_loss: 3.6341\n",
      "Epoch 41/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3469 - loss: 3.3981 - val_accuracy: 0.3457 - val_loss: 3.5925\n",
      "Epoch 42/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3527 - loss: 3.3576 - val_accuracy: 0.3462 - val_loss: 3.5796\n",
      "Epoch 43/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3528 - loss: 3.3520 - val_accuracy: 0.3435 - val_loss: 3.5554\n",
      "Epoch 44/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3548 - loss: 3.3388 - val_accuracy: 0.3455 - val_loss: 3.5561\n",
      "Epoch 45/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3550 - loss: 3.3330 - val_accuracy: 0.3479 - val_loss: 3.5493\n",
      "Epoch 46/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - accuracy: 0.3533 - loss: 3.3461 - val_accuracy: 0.3532 - val_loss: 3.5238\n",
      "Epoch 47/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3572 - loss: 3.3155 - val_accuracy: 0.3534 - val_loss: 3.5005\n",
      "Epoch 48/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3598 - loss: 3.2943 - val_accuracy: 0.3523 - val_loss: 3.5125\n",
      "Epoch 49/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3603 - loss: 3.2915 - val_accuracy: 0.3546 - val_loss: 3.4915\n",
      "Epoch 50/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3579 - loss: 3.3045 - val_accuracy: 0.3567 - val_loss: 3.4700\n",
      "Epoch 51/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3610 - loss: 3.2829 - val_accuracy: 0.3539 - val_loss: 3.4699\n",
      "Epoch 52/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - accuracy: 0.3620 - loss: 3.2722 - val_accuracy: 0.3566 - val_loss: 3.4606\n",
      "Epoch 53/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3647 - loss: 3.2542 - val_accuracy: 0.3569 - val_loss: 3.4507\n",
      "Epoch 54/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3640 - loss: 3.2555 - val_accuracy: 0.3589 - val_loss: 3.4443\n",
      "Epoch 55/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3650 - loss: 3.2478 - val_accuracy: 0.3555 - val_loss: 3.4373\n",
      "Epoch 56/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3650 - loss: 3.2459 - val_accuracy: 0.3613 - val_loss: 3.4336\n",
      "Epoch 57/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3643 - loss: 3.2525 - val_accuracy: 0.3602 - val_loss: 3.4040\n",
      "Epoch 58/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3679 - loss: 3.2257 - val_accuracy: 0.3623 - val_loss: 3.4222\n",
      "Epoch 59/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3642 - loss: 3.2534 - val_accuracy: 0.3608 - val_loss: 3.4271\n",
      "Epoch 60/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3648 - loss: 3.2427 - val_accuracy: 0.3665 - val_loss: 3.3870\n",
      "Epoch 61/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3701 - loss: 3.2075 - val_accuracy: 0.3696 - val_loss: 3.3649\n",
      "Epoch 62/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3717 - loss: 3.1954 - val_accuracy: 0.3680 - val_loss: 3.3686\n",
      "Epoch 63/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3707 - loss: 3.2021 - val_accuracy: 0.3726 - val_loss: 3.3645\n",
      "Epoch 64/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3716 - loss: 3.1929 - val_accuracy: 0.3708 - val_loss: 3.3514\n",
      "Epoch 65/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3722 - loss: 3.1876 - val_accuracy: 0.3728 - val_loss: 3.3482\n",
      "Epoch 66/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3713 - loss: 3.1896 - val_accuracy: 0.3715 - val_loss: 3.3350\n",
      "Epoch 67/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3730 - loss: 3.1800 - val_accuracy: 0.3733 - val_loss: 3.3491\n",
      "Epoch 68/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3719 - loss: 3.1895 - val_accuracy: 0.3693 - val_loss: 3.3432\n",
      "Epoch 69/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 87ms/step - accuracy: 0.3699 - loss: 3.1979 - val_accuracy: 0.3700 - val_loss: 3.3276\n",
      "Epoch 70/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 88ms/step - accuracy: 0.3735 - loss: 3.1722 - val_accuracy: 0.3766 - val_loss: 3.3242\n",
      "Epoch 71/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 88ms/step - accuracy: 0.3751 - loss: 3.1596 - val_accuracy: 0.3717 - val_loss: 3.3203\n",
      "Epoch 72/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3760 - loss: 3.1551 - val_accuracy: 0.3727 - val_loss: 3.3215\n",
      "Epoch 73/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3753 - loss: 3.1563 - val_accuracy: 0.3726 - val_loss: 3.3107\n",
      "Epoch 74/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3766 - loss: 3.1463 - val_accuracy: 0.3726 - val_loss: 3.3181\n",
      "Epoch 75/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3772 - loss: 3.1471 - val_accuracy: 0.3761 - val_loss: 3.2930\n",
      "Epoch 76/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3771 - loss: 3.1444 - val_accuracy: 0.3753 - val_loss: 3.3027\n",
      "Epoch 77/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3778 - loss: 3.1382 - val_accuracy: 0.3767 - val_loss: 3.2932\n",
      "Epoch 78/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3753 - loss: 3.1558 - val_accuracy: 0.3747 - val_loss: 3.2929\n",
      "Epoch 79/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 95ms/step - accuracy: 0.3795 - loss: 3.1223 - val_accuracy: 0.3775 - val_loss: 3.2777\n",
      "Epoch 80/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 99ms/step - accuracy: 0.3794 - loss: 3.1213 - val_accuracy: 0.3773 - val_loss: 3.2675\n",
      "Epoch 81/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 97ms/step - accuracy: 0.3795 - loss: 3.1232 - val_accuracy: 0.3761 - val_loss: 3.2762\n",
      "Epoch 82/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 99ms/step - accuracy: 0.3794 - loss: 3.1235 - val_accuracy: 0.3790 - val_loss: 3.2721\n",
      "Epoch 83/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 100ms/step - accuracy: 0.3807 - loss: 3.1121 - val_accuracy: 0.3782 - val_loss: 3.2723\n",
      "Epoch 84/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 100ms/step - accuracy: 0.3809 - loss: 3.1112 - val_accuracy: 0.3796 - val_loss: 3.2803\n",
      "Epoch 85/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 100ms/step - accuracy: 0.3782 - loss: 3.1305 - val_accuracy: 0.3789 - val_loss: 3.2608\n",
      "Epoch 86/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - accuracy: 0.3777 - loss: 3.1311 - val_accuracy: 0.3751 - val_loss: 3.2567\n",
      "Epoch 87/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 98ms/step - accuracy: 0.3783 - loss: 3.1269 - val_accuracy: 0.3796 - val_loss: 3.2621\n",
      "Epoch 88/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 107ms/step - accuracy: 0.3777 - loss: 3.1314 - val_accuracy: 0.3797 - val_loss: 3.2456\n",
      "Epoch 89/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 107ms/step - accuracy: 0.3827 - loss: 3.0969 - val_accuracy: 0.3798 - val_loss: 3.2415\n",
      "Epoch 90/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 104ms/step - accuracy: 0.3836 - loss: 3.0885 - val_accuracy: 0.3820 - val_loss: 3.2288\n",
      "Restoring model weights from the end of the best epoch: 90.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "model_save_path = './word_arch_class_lr01-2.keras'\n",
    "#model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd26dd9-1fc4-43fb-897f-007db54d72fb",
   "metadata": {},
   "source": [
    "Mejoro bastante la metrica de accuracy y completo las 90 epochs con lo cual, si se entrenase mas, parece que podria seguir mejorando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a1f05-b2a9-4547-b9e2-3adea8cadc9a",
   "metadata": {},
   "source": [
    "## Capa Bidirectional para LSTM\n",
    "\n",
    "Ahora probamos agregar bidireccion en las capas LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "30c2168b-2bdf-4068-86dd-26704c390164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">377,952</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5002</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">165,066</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_33 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m1,280,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m248\u001b[0m)        │       \u001b[38;5;34m377,952\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m248\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m160,256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5002\u001b[0m)           │       \u001b[38;5;34m165,066\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,987,658</span> (7.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,987,658\u001b[0m (7.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,987,658</span> (7.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,987,658\u001b[0m (7.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "embedding_dim = 256 \n",
    "rnn_units = 124 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.Bidirectional(layers.LSTM(rnn_units, return_sequences=True)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(vocab_size+1, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 1024\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ef5d0ea-17f2-452f-9584-aff2418c94b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.1326 - loss: 5.6627 - val_accuracy: 0.2130 - val_loss: 5.0311\n",
      "Epoch 2/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 18ms/step - accuracy: 0.2066 - loss: 4.7165 - val_accuracy: 0.2312 - val_loss: 4.8481\n",
      "Epoch 3/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 18ms/step - accuracy: 0.2371 - loss: 4.4592 - val_accuracy: 0.2331 - val_loss: 4.7490\n",
      "Epoch 4/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 18ms/step - accuracy: 0.2529 - loss: 4.3280 - val_accuracy: 0.2385 - val_loss: 4.6772\n",
      "Epoch 5/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 18ms/step - accuracy: 0.2603 - loss: 4.2422 - val_accuracy: 0.2469 - val_loss: 4.6016\n",
      "Epoch 6/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 18ms/step - accuracy: 0.2650 - loss: 4.1812 - val_accuracy: 0.2472 - val_loss: 4.5606\n",
      "Epoch 7/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 18ms/step - accuracy: 0.2694 - loss: 4.1278 - val_accuracy: 0.2497 - val_loss: 4.4916\n",
      "Epoch 8/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.2728 - loss: 4.0865 - val_accuracy: 0.2515 - val_loss: 4.4645\n",
      "Epoch 9/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.2756 - loss: 4.0499 - val_accuracy: 0.2580 - val_loss: 4.4369\n",
      "Epoch 10/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.2792 - loss: 4.0146 - val_accuracy: 0.2633 - val_loss: 4.3802\n",
      "Epoch 11/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.2816 - loss: 3.9879 - val_accuracy: 0.2642 - val_loss: 4.3567\n",
      "Epoch 12/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.2845 - loss: 3.9566 - val_accuracy: 0.2645 - val_loss: 4.3255\n",
      "Epoch 13/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.2868 - loss: 3.9319 - val_accuracy: 0.2640 - val_loss: 4.3059\n",
      "Epoch 14/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.2883 - loss: 3.9060 - val_accuracy: 0.2692 - val_loss: 4.2842\n",
      "Epoch 15/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.2908 - loss: 3.8851 - val_accuracy: 0.2695 - val_loss: 4.2620\n",
      "Epoch 16/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.2931 - loss: 3.8598 - val_accuracy: 0.2737 - val_loss: 4.2332\n",
      "Epoch 17/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.2947 - loss: 3.8465 - val_accuracy: 0.2769 - val_loss: 4.2195\n",
      "Epoch 18/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.2969 - loss: 3.8222 - val_accuracy: 0.2785 - val_loss: 4.1856\n",
      "Epoch 19/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.2984 - loss: 3.8059 - val_accuracy: 0.2790 - val_loss: 4.1745\n",
      "Epoch 20/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3005 - loss: 3.7901 - val_accuracy: 0.2840 - val_loss: 4.1539\n",
      "Epoch 21/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3014 - loss: 3.7739 - val_accuracy: 0.2816 - val_loss: 4.1362\n",
      "Epoch 22/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3025 - loss: 3.7630 - val_accuracy: 0.2832 - val_loss: 4.1134\n",
      "Epoch 23/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3046 - loss: 3.7456 - val_accuracy: 0.2857 - val_loss: 4.1043\n",
      "Epoch 24/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 18ms/step - accuracy: 0.3059 - loss: 3.7321 - val_accuracy: 0.2875 - val_loss: 4.0971\n",
      "Epoch 25/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3074 - loss: 3.7228 - val_accuracy: 0.2886 - val_loss: 4.0644\n",
      "Epoch 26/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3086 - loss: 3.7102 - val_accuracy: 0.2914 - val_loss: 4.0614\n",
      "Epoch 27/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3087 - loss: 3.7032 - val_accuracy: 0.2942 - val_loss: 4.0415\n",
      "Epoch 28/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3107 - loss: 3.6910 - val_accuracy: 0.2923 - val_loss: 4.0467\n",
      "Epoch 29/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3113 - loss: 3.6800 - val_accuracy: 0.2929 - val_loss: 4.0312\n",
      "Epoch 30/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3114 - loss: 3.6781 - val_accuracy: 0.2950 - val_loss: 4.0267\n",
      "Epoch 31/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3128 - loss: 3.6646 - val_accuracy: 0.2937 - val_loss: 4.0208\n",
      "Epoch 32/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3133 - loss: 3.6578 - val_accuracy: 0.2946 - val_loss: 4.0032\n",
      "Epoch 33/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3146 - loss: 3.6488 - val_accuracy: 0.2996 - val_loss: 3.9867\n",
      "Epoch 34/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3151 - loss: 3.6433 - val_accuracy: 0.2933 - val_loss: 3.9955\n",
      "Epoch 35/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3155 - loss: 3.6399 - val_accuracy: 0.2966 - val_loss: 3.9781\n",
      "Epoch 36/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3167 - loss: 3.6310 - val_accuracy: 0.2996 - val_loss: 3.9639\n",
      "Epoch 37/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3165 - loss: 3.6248 - val_accuracy: 0.3004 - val_loss: 3.9599\n",
      "Epoch 38/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3174 - loss: 3.6213 - val_accuracy: 0.3015 - val_loss: 3.9725\n",
      "Epoch 39/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3172 - loss: 3.6182 - val_accuracy: 0.3019 - val_loss: 3.9557\n",
      "Epoch 40/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3185 - loss: 3.6090 - val_accuracy: 0.2967 - val_loss: 3.9538\n",
      "Epoch 41/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.3190 - loss: 3.6072 - val_accuracy: 0.2979 - val_loss: 3.9592\n",
      "Epoch 42/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.3187 - loss: 3.6044 - val_accuracy: 0.3000 - val_loss: 3.9453\n",
      "Epoch 43/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3192 - loss: 3.6016 - val_accuracy: 0.2980 - val_loss: 3.9451\n",
      "Epoch 44/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3200 - loss: 3.5939 - val_accuracy: 0.3003 - val_loss: 3.9403\n",
      "Epoch 45/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3199 - loss: 3.5924 - val_accuracy: 0.2981 - val_loss: 3.9373\n",
      "Epoch 46/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.3205 - loss: 3.5874 - val_accuracy: 0.2996 - val_loss: 3.9223\n",
      "Epoch 47/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3201 - loss: 3.5874 - val_accuracy: 0.3011 - val_loss: 3.9223\n",
      "Epoch 48/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3209 - loss: 3.5849 - val_accuracy: 0.3003 - val_loss: 3.9172\n",
      "Epoch 49/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3213 - loss: 3.5829 - val_accuracy: 0.3008 - val_loss: 3.9293\n",
      "Epoch 50/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3215 - loss: 3.5760 - val_accuracy: 0.3007 - val_loss: 3.9102\n",
      "Epoch 51/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3216 - loss: 3.5768 - val_accuracy: 0.3028 - val_loss: 3.9152\n",
      "Epoch 52/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3224 - loss: 3.5710 - val_accuracy: 0.3035 - val_loss: 3.8899\n",
      "Epoch 53/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3219 - loss: 3.5709 - val_accuracy: 0.3009 - val_loss: 3.9058\n",
      "Epoch 54/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3228 - loss: 3.5662 - val_accuracy: 0.3002 - val_loss: 3.9226\n",
      "Epoch 55/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3234 - loss: 3.5635 - val_accuracy: 0.2985 - val_loss: 3.9118\n",
      "Epoch 56/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3231 - loss: 3.5629 - val_accuracy: 0.3058 - val_loss: 3.9012\n",
      "Epoch 57/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 19ms/step - accuracy: 0.3228 - loss: 3.5620 - val_accuracy: 0.3017 - val_loss: 3.9032\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8df6d1a-f1f5-4b7e-b73f-7debaaf3e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_arch_class_brnn_lr01-1.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1715581-e61b-4e6a-845c-ef78414a8bde",
   "metadata": {},
   "source": [
    "Dio mejor que la arquitectura sin bidireccion y con los mismos parametros de embedding y rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79ef0297-ec79-4d98-baf2-6ca5be0222cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5001</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">645,129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m1,280,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5001\u001b[0m)           │       \u001b[38;5;34m645,129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,205,065</span> (8.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,205,065\u001b[0m (8.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,205,065</span> (8.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,205,065\u001b[0m (8.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "embedding_dim = 256 \n",
    "rnn_units = 64 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.Bidirectional(layers.LSTM(rnn_units, return_sequences=True)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 512\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f88e304-01e8-4e65-8006-475fc91d2233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.1436 - loss: 5.5230 - val_accuracy: 0.2164 - val_loss: 4.9483\n",
      "Epoch 2/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2208 - loss: 4.5258 - val_accuracy: 0.2302 - val_loss: 4.7333\n",
      "Epoch 3/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2492 - loss: 4.2859 - val_accuracy: 0.2381 - val_loss: 4.6028\n",
      "Epoch 4/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2580 - loss: 4.1699 - val_accuracy: 0.2410 - val_loss: 4.5244\n",
      "Epoch 5/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2626 - loss: 4.0945 - val_accuracy: 0.2443 - val_loss: 4.4611\n",
      "Epoch 6/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2659 - loss: 4.0439 - val_accuracy: 0.2478 - val_loss: 4.4088\n",
      "Epoch 7/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2700 - loss: 3.9904 - val_accuracy: 0.2516 - val_loss: 4.3667\n",
      "Epoch 8/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2714 - loss: 3.9576 - val_accuracy: 0.2538 - val_loss: 4.3356\n",
      "Epoch 9/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2748 - loss: 3.9188 - val_accuracy: 0.2524 - val_loss: 4.3194\n",
      "Epoch 10/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2771 - loss: 3.8896 - val_accuracy: 0.2599 - val_loss: 4.2633\n",
      "Epoch 11/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2792 - loss: 3.8632 - val_accuracy: 0.2609 - val_loss: 4.2444\n",
      "Epoch 12/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2813 - loss: 3.8362 - val_accuracy: 0.2623 - val_loss: 4.2136\n",
      "Epoch 13/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2828 - loss: 3.8181 - val_accuracy: 0.2620 - val_loss: 4.2031\n",
      "Epoch 14/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2840 - loss: 3.7943 - val_accuracy: 0.2628 - val_loss: 4.1781\n",
      "Epoch 15/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2864 - loss: 3.7750 - val_accuracy: 0.2671 - val_loss: 4.1510\n",
      "Epoch 16/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2878 - loss: 3.7544 - val_accuracy: 0.2653 - val_loss: 4.1305\n",
      "Epoch 17/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2889 - loss: 3.7385 - val_accuracy: 0.2703 - val_loss: 4.1093\n",
      "Epoch 18/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2900 - loss: 3.7218 - val_accuracy: 0.2699 - val_loss: 4.0959\n",
      "Epoch 19/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2917 - loss: 3.7053 - val_accuracy: 0.2693 - val_loss: 4.0824\n",
      "Epoch 20/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 14ms/step - accuracy: 0.2920 - loss: 3.6961 - val_accuracy: 0.2692 - val_loss: 4.0855\n",
      "Epoch 21/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2932 - loss: 3.6793 - val_accuracy: 0.2691 - val_loss: 4.0456\n",
      "Epoch 22/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2946 - loss: 3.6693 - val_accuracy: 0.2719 - val_loss: 4.0299\n",
      "Epoch 23/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2953 - loss: 3.6605 - val_accuracy: 0.2723 - val_loss: 4.0213\n",
      "Epoch 24/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2965 - loss: 3.6463 - val_accuracy: 0.2777 - val_loss: 4.0005\n",
      "Epoch 25/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2972 - loss: 3.6359 - val_accuracy: 0.2744 - val_loss: 3.9931\n",
      "Epoch 26/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2981 - loss: 3.6266 - val_accuracy: 0.2756 - val_loss: 3.9836\n",
      "Epoch 27/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2987 - loss: 3.6171 - val_accuracy: 0.2762 - val_loss: 3.9707\n",
      "Epoch 28/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.2996 - loss: 3.6081 - val_accuracy: 0.2781 - val_loss: 3.9624\n",
      "Epoch 29/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3000 - loss: 3.6032 - val_accuracy: 0.2797 - val_loss: 3.9475\n",
      "Epoch 30/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3007 - loss: 3.5941 - val_accuracy: 0.2789 - val_loss: 3.9400\n",
      "Epoch 31/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3017 - loss: 3.5883 - val_accuracy: 0.2791 - val_loss: 3.9249\n",
      "Epoch 32/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3017 - loss: 3.5796 - val_accuracy: 0.2786 - val_loss: 3.9232\n",
      "Epoch 33/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3035 - loss: 3.5700 - val_accuracy: 0.2817 - val_loss: 3.9035\n",
      "Epoch 34/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3033 - loss: 3.5678 - val_accuracy: 0.2822 - val_loss: 3.9046\n",
      "Epoch 35/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3037 - loss: 3.5616 - val_accuracy: 0.2824 - val_loss: 3.8967\n",
      "Epoch 36/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3046 - loss: 3.5536 - val_accuracy: 0.2834 - val_loss: 3.8859\n",
      "Epoch 37/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3050 - loss: 3.5500 - val_accuracy: 0.2825 - val_loss: 3.8831\n",
      "Epoch 38/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3057 - loss: 3.5437 - val_accuracy: 0.2829 - val_loss: 3.8776\n",
      "Epoch 39/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3058 - loss: 3.5389 - val_accuracy: 0.2830 - val_loss: 3.8832\n",
      "Epoch 40/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3062 - loss: 3.5351 - val_accuracy: 0.2876 - val_loss: 3.8585\n",
      "Epoch 41/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3062 - loss: 3.5298 - val_accuracy: 0.2845 - val_loss: 3.8673\n",
      "Epoch 42/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3061 - loss: 3.5287 - val_accuracy: 0.2835 - val_loss: 3.8574\n",
      "Epoch 43/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3071 - loss: 3.5202 - val_accuracy: 0.2859 - val_loss: 3.8558\n",
      "Epoch 44/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3075 - loss: 3.5191 - val_accuracy: 0.2848 - val_loss: 3.8468\n",
      "Epoch 45/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3078 - loss: 3.5140 - val_accuracy: 0.2860 - val_loss: 3.8381\n",
      "Epoch 46/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3081 - loss: 3.5141 - val_accuracy: 0.2871 - val_loss: 3.8386\n",
      "Epoch 47/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3082 - loss: 3.5085 - val_accuracy: 0.2849 - val_loss: 3.8339\n",
      "Epoch 48/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 14ms/step - accuracy: 0.3086 - loss: 3.5022 - val_accuracy: 0.2869 - val_loss: 3.8322\n",
      "Epoch 49/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3097 - loss: 3.4993 - val_accuracy: 0.2864 - val_loss: 3.8167\n",
      "Epoch 50/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3097 - loss: 3.4968 - val_accuracy: 0.2869 - val_loss: 3.8244\n",
      "Epoch 51/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3093 - loss: 3.4958 - val_accuracy: 0.2866 - val_loss: 3.8183\n",
      "Epoch 52/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3095 - loss: 3.4942 - val_accuracy: 0.2903 - val_loss: 3.8092\n",
      "Epoch 53/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3102 - loss: 3.4887 - val_accuracy: 0.2901 - val_loss: 3.8060\n",
      "Epoch 54/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3102 - loss: 3.4884 - val_accuracy: 0.2883 - val_loss: 3.7960\n",
      "Epoch 55/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3102 - loss: 3.4878 - val_accuracy: 0.2870 - val_loss: 3.8101\n",
      "Epoch 56/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3111 - loss: 3.4813 - val_accuracy: 0.2885 - val_loss: 3.7904\n",
      "Epoch 57/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3111 - loss: 3.4815 - val_accuracy: 0.2860 - val_loss: 3.7908\n",
      "Epoch 58/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3110 - loss: 3.4801 - val_accuracy: 0.2891 - val_loss: 3.7919\n",
      "Epoch 59/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3114 - loss: 3.4771 - val_accuracy: 0.2900 - val_loss: 3.7864\n",
      "Epoch 60/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3115 - loss: 3.4753 - val_accuracy: 0.2865 - val_loss: 3.8002\n",
      "Epoch 61/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3118 - loss: 3.4730 - val_accuracy: 0.2910 - val_loss: 3.7933\n",
      "Epoch 62/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3119 - loss: 3.4703 - val_accuracy: 0.2919 - val_loss: 3.7803\n",
      "Epoch 63/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3120 - loss: 3.4672 - val_accuracy: 0.2918 - val_loss: 3.7796\n",
      "Epoch 64/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3128 - loss: 3.4664 - val_accuracy: 0.2889 - val_loss: 3.7902\n",
      "Epoch 65/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3124 - loss: 3.4654 - val_accuracy: 0.2908 - val_loss: 3.7678\n",
      "Epoch 66/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3122 - loss: 3.4699 - val_accuracy: 0.2937 - val_loss: 3.7672\n",
      "Epoch 67/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3125 - loss: 3.4635 - val_accuracy: 0.2878 - val_loss: 3.7747\n",
      "Epoch 68/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 14ms/step - accuracy: 0.3126 - loss: 3.4628 - val_accuracy: 0.2891 - val_loss: 3.7668\n",
      "Epoch 69/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 15ms/step - accuracy: 0.3128 - loss: 3.4626 - val_accuracy: 0.2917 - val_loss: 3.7791\n",
      "Epoch 70/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 15ms/step - accuracy: 0.3128 - loss: 3.4609 - val_accuracy: 0.2892 - val_loss: 3.7661\n",
      "Epoch 71/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 15ms/step - accuracy: 0.3132 - loss: 3.4583 - val_accuracy: 0.2898 - val_loss: 3.7747\n",
      "Epoch 72/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.3128 - loss: 3.4608 - val_accuracy: 0.2897 - val_loss: 3.7700\n",
      "Epoch 73/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.3135 - loss: 3.4542 - val_accuracy: 0.2896 - val_loss: 3.7578\n",
      "Epoch 74/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.3135 - loss: 3.4544 - val_accuracy: 0.2889 - val_loss: 3.7682\n",
      "Epoch 75/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.3129 - loss: 3.4559 - val_accuracy: 0.2868 - val_loss: 3.7738\n",
      "Epoch 76/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.3124 - loss: 3.4587 - val_accuracy: 0.2853 - val_loss: 3.7757\n",
      "Epoch 77/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.3135 - loss: 3.4532 - val_accuracy: 0.2906 - val_loss: 3.7616\n",
      "Epoch 78/90\n",
      "\u001b[1m4445/4445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15ms/step - accuracy: 0.3135 - loss: 3.4521 - val_accuracy: 0.2901 - val_loss: 3.7587\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9ae2d311-7adc-4063-9576-825141e22313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_arch_class_brnn_lr01-2.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6fe7a1dd-5c09-4b14-89ca-e9901a8d1846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature 0.5:\n",
      "It was a dark and stormy night oligarchies spite winged warranties bloody mode gained properly fellow freely fairest commencement accused evening altogether instructed meno presented animal namely\n",
      "\n",
      "Temperature 1.0:\n",
      "It was a dark and stormy night reader deliver avoided slowly matters roar sound everywhere excluded let rises crito waste variety united tend lesson balance perpetual others\n",
      "\n",
      "Temperature 1.2 (different seed):\n",
      "The king declared impression μάλιστα opportunities practised palace position gets indicating hesiod card free αυτήν nations own shine receiving deem blow essence institutions\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a dark and stormy night\"\n",
    "generated_output_temp_0_5 = generate_text(model, start_string=seed_text, num_generate=20, temperature=0.5)\n",
    "# To see the output, you would need to print it:\n",
    "print(f\"\\nTemperature 0.5:\\n{generated_output_temp_0_5}\")\n",
    "\n",
    "generated_output_temp_1_0 = generate_text(model, start_string=seed_text, num_generate=20, temperature=1.0)\n",
    "print(f\"\\nTemperature 1.0:\\n{generated_output_temp_1_0}\")\n",
    "\n",
    "generated_output_temp_1_5 = generate_text(model, start_string=\"The king declared\", num_generate=20, temperature=1.2)\n",
    "print(f\"\\nTemperature 1.2 (different seed):\\n{generated_output_temp_1_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60230010-0476-49d7-b94e-11b1d1e04e95",
   "metadata": {},
   "source": [
    "# Arquitectura con CNN\n",
    "\n",
    "Probamos agregando una capa convolucional a un LSTM simple. Tambien incluimos capas de dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24a6cc70-4580-4ed0-bcec-4f943ef78d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">93,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_feed_forward (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5002</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">625,250</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_26 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m1,280,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m81,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dropout (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m)            │        \u001b[38;5;34m93,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_dropout (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_feed_forward (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5002\u001b[0m)           │       \u001b[38;5;34m625,250\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,081,234</span> (7.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,081,234\u001b[0m (7.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,081,234</span> (7.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,081,234\u001b[0m (7.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "embedding_dim = 256\n",
    "rnn_units = 128\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.Conv1D(filters=64, kernel_size=5, padding='causal', activation='relu'),\n",
    "    layers.Dropout(0.2, name=\"conv_dropout\"),\n",
    "    layers.LSTM(  units=rnn_units, return_sequences=False, name=\"lstm_layer\" ),\n",
    "    layers.Dropout(0.2, name=\"lstm_dropout\"),\n",
    "    layers.Dense(\n",
    "        units=vocab_size+1,\n",
    "        activation='softmax',\n",
    "        name=\"output_feed_forward\"\n",
    "    )\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 1024\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cfea8280-7b41-4fd6-a4c8-3671df14fcc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.1154 - loss: 5.8928 - val_accuracy: 0.2122 - val_loss: 5.1154\n",
      "Epoch 2/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.1899 - loss: 4.9219 - val_accuracy: 0.2222 - val_loss: 4.9396\n",
      "Epoch 3/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2066 - loss: 4.7042 - val_accuracy: 0.2249 - val_loss: 4.8445\n",
      "Epoch 4/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2176 - loss: 4.5790 - val_accuracy: 0.2288 - val_loss: 4.7668\n",
      "Epoch 5/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2283 - loss: 4.4832 - val_accuracy: 0.2349 - val_loss: 4.6999\n",
      "Epoch 6/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2337 - loss: 4.4215 - val_accuracy: 0.2345 - val_loss: 4.6657\n",
      "Epoch 7/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2388 - loss: 4.3716 - val_accuracy: 0.2389 - val_loss: 4.6124\n",
      "Epoch 8/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2430 - loss: 4.3314 - val_accuracy: 0.2446 - val_loss: 4.5682\n",
      "Epoch 9/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2459 - loss: 4.2976 - val_accuracy: 0.2446 - val_loss: 4.5524\n",
      "Epoch 10/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2480 - loss: 4.2691 - val_accuracy: 0.2456 - val_loss: 4.5168\n",
      "Epoch 11/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2498 - loss: 4.2483 - val_accuracy: 0.2474 - val_loss: 4.4920\n",
      "Epoch 12/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.2522 - loss: 4.2228 - val_accuracy: 0.2485 - val_loss: 4.4667\n",
      "Epoch 13/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2535 - loss: 4.2025 - val_accuracy: 0.2499 - val_loss: 4.4386\n",
      "Epoch 14/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2551 - loss: 4.1849 - val_accuracy: 0.2522 - val_loss: 4.4217\n",
      "Epoch 15/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2564 - loss: 4.1697 - val_accuracy: 0.2525 - val_loss: 4.4048\n",
      "Epoch 16/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2568 - loss: 4.1574 - val_accuracy: 0.2544 - val_loss: 4.3860\n",
      "Epoch 17/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2584 - loss: 4.1414 - val_accuracy: 0.2542 - val_loss: 4.3741\n",
      "Epoch 18/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2584 - loss: 4.1327 - val_accuracy: 0.2542 - val_loss: 4.3553\n",
      "Epoch 19/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2600 - loss: 4.1175 - val_accuracy: 0.2562 - val_loss: 4.3409\n",
      "Epoch 20/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2606 - loss: 4.1086 - val_accuracy: 0.2570 - val_loss: 4.3260\n",
      "Epoch 21/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2621 - loss: 4.0967 - val_accuracy: 0.2575 - val_loss: 4.3061\n",
      "Epoch 22/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2618 - loss: 4.0887 - val_accuracy: 0.2566 - val_loss: 4.3004\n",
      "Epoch 23/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2620 - loss: 4.0804 - val_accuracy: 0.2559 - val_loss: 4.2930\n",
      "Epoch 24/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2631 - loss: 4.0726 - val_accuracy: 0.2595 - val_loss: 4.2756\n",
      "Epoch 25/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2639 - loss: 4.0652 - val_accuracy: 0.2628 - val_loss: 4.2580\n",
      "Epoch 26/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2641 - loss: 4.0590 - val_accuracy: 0.2610 - val_loss: 4.2430\n",
      "Epoch 27/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2648 - loss: 4.0512 - val_accuracy: 0.2627 - val_loss: 4.2380\n",
      "Epoch 28/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2651 - loss: 4.0430 - val_accuracy: 0.2643 - val_loss: 4.2273\n",
      "Epoch 29/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2659 - loss: 4.0357 - val_accuracy: 0.2634 - val_loss: 4.2239\n",
      "Epoch 30/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.2659 - loss: 4.0330 - val_accuracy: 0.2603 - val_loss: 4.2189\n",
      "Epoch 31/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2662 - loss: 4.0300 - val_accuracy: 0.2641 - val_loss: 4.2017\n",
      "Epoch 32/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2668 - loss: 4.0211 - val_accuracy: 0.2649 - val_loss: 4.2001\n",
      "Epoch 33/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2669 - loss: 4.0217 - val_accuracy: 0.2693 - val_loss: 4.1845\n",
      "Epoch 34/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2671 - loss: 4.0133 - val_accuracy: 0.2663 - val_loss: 4.1777\n",
      "Epoch 35/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2671 - loss: 4.0111 - val_accuracy: 0.2675 - val_loss: 4.1674\n",
      "Epoch 36/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2675 - loss: 4.0067 - val_accuracy: 0.2651 - val_loss: 4.1679\n",
      "Epoch 37/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2683 - loss: 4.0018 - val_accuracy: 0.2671 - val_loss: 4.1621\n",
      "Epoch 38/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2681 - loss: 3.9987 - val_accuracy: 0.2672 - val_loss: 4.1574\n",
      "Epoch 39/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2686 - loss: 3.9910 - val_accuracy: 0.2685 - val_loss: 4.1516\n",
      "Epoch 40/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2687 - loss: 3.9911 - val_accuracy: 0.2682 - val_loss: 4.1440\n",
      "Epoch 41/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2693 - loss: 3.9906 - val_accuracy: 0.2693 - val_loss: 4.1377\n",
      "Epoch 42/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2694 - loss: 3.9832 - val_accuracy: 0.2714 - val_loss: 4.1268\n",
      "Epoch 43/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2705 - loss: 3.9802 - val_accuracy: 0.2697 - val_loss: 4.1313\n",
      "Epoch 44/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2700 - loss: 3.9780 - val_accuracy: 0.2703 - val_loss: 4.1280\n",
      "Epoch 45/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2695 - loss: 3.9763 - val_accuracy: 0.2719 - val_loss: 4.1203\n",
      "Epoch 46/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2699 - loss: 3.9750 - val_accuracy: 0.2714 - val_loss: 4.1101\n",
      "Epoch 47/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2704 - loss: 3.9689 - val_accuracy: 0.2705 - val_loss: 4.1148\n",
      "Epoch 48/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2706 - loss: 3.9665 - val_accuracy: 0.2730 - val_loss: 4.1171\n",
      "Epoch 49/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2705 - loss: 3.9668 - val_accuracy: 0.2727 - val_loss: 4.1081\n",
      "Epoch 50/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2713 - loss: 3.9614 - val_accuracy: 0.2717 - val_loss: 4.1032\n",
      "Epoch 51/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2709 - loss: 3.9608 - val_accuracy: 0.2719 - val_loss: 4.1055\n",
      "Epoch 52/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2704 - loss: 3.9601 - val_accuracy: 0.2700 - val_loss: 4.0917\n",
      "Epoch 53/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2715 - loss: 3.9561 - val_accuracy: 0.2709 - val_loss: 4.0868\n",
      "Epoch 54/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2719 - loss: 3.9515 - val_accuracy: 0.2738 - val_loss: 4.0899\n",
      "Epoch 55/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2717 - loss: 3.9515 - val_accuracy: 0.2732 - val_loss: 4.0746\n",
      "Epoch 56/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2716 - loss: 3.9518 - val_accuracy: 0.2715 - val_loss: 4.0790\n",
      "Epoch 57/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2714 - loss: 3.9510 - val_accuracy: 0.2743 - val_loss: 4.0703\n",
      "Epoch 58/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2717 - loss: 3.9510 - val_accuracy: 0.2736 - val_loss: 4.0670\n",
      "Epoch 59/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2716 - loss: 3.9485 - val_accuracy: 0.2718 - val_loss: 4.0716\n",
      "Epoch 60/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2723 - loss: 3.9419 - val_accuracy: 0.2741 - val_loss: 4.0690\n",
      "Epoch 61/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2717 - loss: 3.9443 - val_accuracy: 0.2701 - val_loss: 4.0678\n",
      "Epoch 62/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2728 - loss: 3.9406 - val_accuracy: 0.2736 - val_loss: 4.0610\n",
      "Epoch 63/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2723 - loss: 3.9402 - val_accuracy: 0.2736 - val_loss: 4.0684\n",
      "Epoch 64/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2723 - loss: 3.9390 - val_accuracy: 0.2747 - val_loss: 4.0635\n",
      "Epoch 65/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2721 - loss: 3.9389 - val_accuracy: 0.2733 - val_loss: 4.0561\n",
      "Epoch 66/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2729 - loss: 3.9351 - val_accuracy: 0.2776 - val_loss: 4.0585\n",
      "Epoch 67/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2728 - loss: 3.9309 - val_accuracy: 0.2755 - val_loss: 4.0557\n",
      "Epoch 68/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2729 - loss: 3.9312 - val_accuracy: 0.2734 - val_loss: 4.0494\n",
      "Epoch 69/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2727 - loss: 3.9311 - val_accuracy: 0.2742 - val_loss: 4.0495\n",
      "Epoch 70/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2727 - loss: 3.9281 - val_accuracy: 0.2747 - val_loss: 4.0384\n",
      "Epoch 71/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2731 - loss: 3.9288 - val_accuracy: 0.2776 - val_loss: 4.0428\n",
      "Epoch 72/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2729 - loss: 3.9298 - val_accuracy: 0.2764 - val_loss: 4.0441\n",
      "Epoch 73/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2737 - loss: 3.9273 - val_accuracy: 0.2754 - val_loss: 4.0421\n",
      "Epoch 74/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2738 - loss: 3.9248 - val_accuracy: 0.2776 - val_loss: 4.0398\n",
      "Epoch 75/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2730 - loss: 3.9244 - val_accuracy: 0.2774 - val_loss: 4.0266\n",
      "Epoch 76/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2734 - loss: 3.9222 - val_accuracy: 0.2769 - val_loss: 4.0335\n",
      "Epoch 77/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2742 - loss: 3.9191 - val_accuracy: 0.2772 - val_loss: 4.0234\n",
      "Epoch 78/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2733 - loss: 3.9227 - val_accuracy: 0.2749 - val_loss: 4.0268\n",
      "Epoch 79/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2735 - loss: 3.9200 - val_accuracy: 0.2763 - val_loss: 4.0277\n",
      "Epoch 80/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2737 - loss: 3.9199 - val_accuracy: 0.2768 - val_loss: 4.0249\n",
      "Epoch 81/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2735 - loss: 3.9184 - val_accuracy: 0.2768 - val_loss: 4.0308\n",
      "Epoch 82/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.2738 - loss: 3.9177 - val_accuracy: 0.2770 - val_loss: 4.0327\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5daf8cd1-1831-4fa5-8441-e148fd7aab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_arch_class_cnn-1.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99984d81-f22b-4924-8683-3490f6ad8b11",
   "metadata": {},
   "source": [
    "Dio peor accuracy que el modelo simple LSTM.\n",
    "\n",
    "Probamos incrementando la recurrencia y la dimension del embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e15a496-0b7e-41af-9def-457f9eeb0af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_feed_forward (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5001</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565,513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_31 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m2,560,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m163,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dropout (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,181,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_dropout (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_feed_forward (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5001\u001b[0m)           │     \u001b[38;5;34m2,565,513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,471,625</span> (24.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,471,625\u001b[0m (24.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,471,625</span> (24.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,471,625\u001b[0m (24.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "embedding_dim = 512\n",
    "rnn_units = 512\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.Conv1D(filters=64, kernel_size=5, padding='causal', activation='relu'),\n",
    "    layers.Dropout(0.2, name=\"conv_dropout\"),\n",
    "    layers.LSTM(  units=rnn_units, return_sequences=False, name=\"lstm_layer\" ),\n",
    "    layers.Dropout(0.2, name=\"lstm_dropout\"),\n",
    "    layers.Dense(\n",
    "        units=vocab_size,\n",
    "        activation='softmax',\n",
    "        name=\"output_feed_forward\"\n",
    "    )\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90\n",
    "batch_size = 2048\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45832545-679f-48e4-b8cb-2e101c547926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.1334 - loss: 5.6755 - val_accuracy: 0.2139 - val_loss: 5.0242\n",
      "Epoch 2/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 69ms/step - accuracy: 0.2013 - loss: 4.7390 - val_accuracy: 0.2244 - val_loss: 4.8246\n",
      "Epoch 3/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2237 - loss: 4.5047 - val_accuracy: 0.2301 - val_loss: 4.7135\n",
      "Epoch 4/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2376 - loss: 4.3611 - val_accuracy: 0.2363 - val_loss: 4.6208\n",
      "Epoch 5/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2470 - loss: 4.2600 - val_accuracy: 0.2411 - val_loss: 4.5345\n",
      "Epoch 6/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2530 - loss: 4.1817 - val_accuracy: 0.2464 - val_loss: 4.4461\n",
      "Epoch 7/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2579 - loss: 4.1236 - val_accuracy: 0.2479 - val_loss: 4.4053\n",
      "Epoch 8/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2617 - loss: 4.0702 - val_accuracy: 0.2508 - val_loss: 4.3515\n",
      "Epoch 9/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2643 - loss: 4.0249 - val_accuracy: 0.2531 - val_loss: 4.3050\n",
      "Epoch 10/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2669 - loss: 3.9869 - val_accuracy: 0.2537 - val_loss: 4.2565\n",
      "Epoch 11/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2692 - loss: 3.9536 - val_accuracy: 0.2576 - val_loss: 4.2224\n",
      "Epoch 12/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2712 - loss: 3.9208 - val_accuracy: 0.2613 - val_loss: 4.1632\n",
      "Epoch 13/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2726 - loss: 3.8912 - val_accuracy: 0.2603 - val_loss: 4.1471\n",
      "Epoch 14/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2744 - loss: 3.8656 - val_accuracy: 0.2612 - val_loss: 4.1004\n",
      "Epoch 15/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2754 - loss: 3.8444 - val_accuracy: 0.2675 - val_loss: 4.0603\n",
      "Epoch 16/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2769 - loss: 3.8206 - val_accuracy: 0.2660 - val_loss: 4.0375\n",
      "Epoch 17/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2791 - loss: 3.7977 - val_accuracy: 0.2652 - val_loss: 4.0128\n",
      "Epoch 18/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2800 - loss: 3.7773 - val_accuracy: 0.2645 - val_loss: 3.9830\n",
      "Epoch 19/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2807 - loss: 3.7556 - val_accuracy: 0.2693 - val_loss: 3.9525\n",
      "Epoch 20/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - accuracy: 0.2824 - loss: 3.7389 - val_accuracy: 0.2704 - val_loss: 3.9361\n",
      "Epoch 21/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 70ms/step - accuracy: 0.2831 - loss: 3.7214 - val_accuracy: 0.2738 - val_loss: 3.8986\n",
      "Epoch 22/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 70ms/step - accuracy: 0.2842 - loss: 3.7110 - val_accuracy: 0.2707 - val_loss: 3.8803\n",
      "Epoch 23/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2855 - loss: 3.6905 - val_accuracy: 0.2731 - val_loss: 3.8470\n",
      "Epoch 24/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2866 - loss: 3.6719 - val_accuracy: 0.2732 - val_loss: 3.8358\n",
      "Epoch 25/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2877 - loss: 3.6593 - val_accuracy: 0.2762 - val_loss: 3.8157\n",
      "Epoch 26/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2878 - loss: 3.6491 - val_accuracy: 0.2746 - val_loss: 3.7881\n",
      "Epoch 27/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2890 - loss: 3.6364 - val_accuracy: 0.2768 - val_loss: 3.7759\n",
      "Epoch 28/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2897 - loss: 3.6271 - val_accuracy: 0.2751 - val_loss: 3.7585\n",
      "Epoch 29/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2898 - loss: 3.6159 - val_accuracy: 0.2752 - val_loss: 3.7348\n",
      "Epoch 30/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2920 - loss: 3.5990 - val_accuracy: 0.2795 - val_loss: 3.7255\n",
      "Epoch 31/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2919 - loss: 3.5928 - val_accuracy: 0.2819 - val_loss: 3.6924\n",
      "Epoch 32/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2925 - loss: 3.5815 - val_accuracy: 0.2836 - val_loss: 3.6785\n",
      "Epoch 33/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2936 - loss: 3.5718 - val_accuracy: 0.2801 - val_loss: 3.6797\n",
      "Epoch 34/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2939 - loss: 3.5621 - val_accuracy: 0.2829 - val_loss: 3.6500\n",
      "Epoch 35/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2946 - loss: 3.5567 - val_accuracy: 0.2837 - val_loss: 3.6473\n",
      "Epoch 36/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2949 - loss: 3.5493 - val_accuracy: 0.2863 - val_loss: 3.6252\n",
      "Epoch 37/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2955 - loss: 3.5429 - val_accuracy: 0.2870 - val_loss: 3.6011\n",
      "Epoch 38/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2962 - loss: 3.5343 - val_accuracy: 0.2887 - val_loss: 3.5882\n",
      "Epoch 39/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2967 - loss: 3.5268 - val_accuracy: 0.2883 - val_loss: 3.5752\n",
      "Epoch 40/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2967 - loss: 3.5225 - val_accuracy: 0.2901 - val_loss: 3.5806\n",
      "Epoch 41/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2970 - loss: 3.5189 - val_accuracy: 0.2898 - val_loss: 3.5548\n",
      "Epoch 42/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 70ms/step - accuracy: 0.2980 - loss: 3.5045 - val_accuracy: 0.2903 - val_loss: 3.5475\n",
      "Epoch 43/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2981 - loss: 3.4995 - val_accuracy: 0.2927 - val_loss: 3.5294\n",
      "Epoch 44/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2984 - loss: 3.4958 - val_accuracy: 0.2916 - val_loss: 3.5206\n",
      "Epoch 45/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3001 - loss: 3.4876 - val_accuracy: 0.2910 - val_loss: 3.5233\n",
      "Epoch 46/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2987 - loss: 3.4895 - val_accuracy: 0.2947 - val_loss: 3.5030\n",
      "Epoch 47/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3003 - loss: 3.4771 - val_accuracy: 0.2962 - val_loss: 3.4838\n",
      "Epoch 48/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.2999 - loss: 3.4774 - val_accuracy: 0.2957 - val_loss: 3.4902\n",
      "Epoch 49/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3007 - loss: 3.4680 - val_accuracy: 0.2962 - val_loss: 3.4958\n",
      "Epoch 50/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3010 - loss: 3.4675 - val_accuracy: 0.2985 - val_loss: 3.4606\n",
      "Epoch 51/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3024 - loss: 3.4568 - val_accuracy: 0.2988 - val_loss: 3.4610\n",
      "Epoch 52/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3016 - loss: 3.4585 - val_accuracy: 0.2997 - val_loss: 3.4509\n",
      "Epoch 53/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3023 - loss: 3.4509 - val_accuracy: 0.2990 - val_loss: 3.4536\n",
      "Epoch 54/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3015 - loss: 3.4567 - val_accuracy: 0.2988 - val_loss: 3.4410\n",
      "Epoch 55/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3023 - loss: 3.4466 - val_accuracy: 0.3010 - val_loss: 3.4244\n",
      "Epoch 56/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3031 - loss: 3.4417 - val_accuracy: 0.3006 - val_loss: 3.4295\n",
      "Epoch 57/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3037 - loss: 3.4369 - val_accuracy: 0.3010 - val_loss: 3.4244\n",
      "Epoch 58/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3034 - loss: 3.4336 - val_accuracy: 0.3032 - val_loss: 3.4031\n",
      "Epoch 59/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3039 - loss: 3.4242 - val_accuracy: 0.3021 - val_loss: 3.4070\n",
      "Epoch 60/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3039 - loss: 3.4267 - val_accuracy: 0.3036 - val_loss: 3.3934\n",
      "Epoch 61/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 71ms/step - accuracy: 0.3048 - loss: 3.4209 - val_accuracy: 0.2998 - val_loss: 3.4015\n",
      "Epoch 62/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3051 - loss: 3.4208 - val_accuracy: 0.3037 - val_loss: 3.3854\n",
      "Epoch 63/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3044 - loss: 3.4207 - val_accuracy: 0.3063 - val_loss: 3.3780\n",
      "Epoch 64/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3050 - loss: 3.4123 - val_accuracy: 0.3047 - val_loss: 3.3680\n",
      "Epoch 65/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3051 - loss: 3.4095 - val_accuracy: 0.3076 - val_loss: 3.3557\n",
      "Epoch 66/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3056 - loss: 3.4075 - val_accuracy: 0.3067 - val_loss: 3.3479\n",
      "Epoch 67/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3060 - loss: 3.4019 - val_accuracy: 0.3060 - val_loss: 3.3512\n",
      "Epoch 68/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3061 - loss: 3.4002 - val_accuracy: 0.3063 - val_loss: 3.3540\n",
      "Epoch 69/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3055 - loss: 3.4037 - val_accuracy: 0.3053 - val_loss: 3.3724\n",
      "Epoch 70/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3055 - loss: 3.4084 - val_accuracy: 0.3066 - val_loss: 3.3321\n",
      "Epoch 71/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3066 - loss: 3.3968 - val_accuracy: 0.3063 - val_loss: 3.3346\n",
      "Epoch 72/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3073 - loss: 3.3900 - val_accuracy: 0.3092 - val_loss: 3.3218\n",
      "Epoch 73/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3071 - loss: 3.3878 - val_accuracy: 0.3032 - val_loss: 3.3326\n",
      "Epoch 74/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3070 - loss: 3.3855 - val_accuracy: 0.3053 - val_loss: 3.3241\n",
      "Epoch 75/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3064 - loss: 3.3872 - val_accuracy: 0.3100 - val_loss: 3.3098\n",
      "Epoch 76/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3073 - loss: 3.3823 - val_accuracy: 0.3136 - val_loss: 3.3127\n",
      "Epoch 77/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3069 - loss: 3.3830 - val_accuracy: 0.3103 - val_loss: 3.3047\n",
      "Epoch 78/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 71ms/step - accuracy: 0.3079 - loss: 3.3782 - val_accuracy: 0.3099 - val_loss: 3.3005\n",
      "Epoch 79/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - accuracy: 0.3081 - loss: 3.3751 - val_accuracy: 0.3105 - val_loss: 3.3055\n",
      "Epoch 80/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 79ms/step - accuracy: 0.3083 - loss: 3.3718 - val_accuracy: 0.3137 - val_loss: 3.3003\n",
      "Epoch 81/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 81ms/step - accuracy: 0.3078 - loss: 3.3741 - val_accuracy: 0.3125 - val_loss: 3.2913\n",
      "Epoch 82/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 81ms/step - accuracy: 0.3070 - loss: 3.3759 - val_accuracy: 0.3121 - val_loss: 3.2812\n",
      "Epoch 83/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - accuracy: 0.3085 - loss: 3.3676 - val_accuracy: 0.3136 - val_loss: 3.2768\n",
      "Epoch 84/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 82ms/step - accuracy: 0.3083 - loss: 3.3667 - val_accuracy: 0.3089 - val_loss: 3.2838\n",
      "Epoch 85/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 76ms/step - accuracy: 0.3094 - loss: 3.3609 - val_accuracy: 0.3174 - val_loss: 3.2694\n",
      "Epoch 86/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 91ms/step - accuracy: 0.3094 - loss: 3.3603 - val_accuracy: 0.3164 - val_loss: 3.2791\n",
      "Epoch 87/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 91ms/step - accuracy: 0.3092 - loss: 3.3603 - val_accuracy: 0.3154 - val_loss: 3.2742\n",
      "Epoch 88/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 91ms/step - accuracy: 0.3082 - loss: 3.3639 - val_accuracy: 0.3146 - val_loss: 3.2625\n",
      "Epoch 89/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 91ms/step - accuracy: 0.3104 - loss: 3.3527 - val_accuracy: 0.3145 - val_loss: 3.2522\n",
      "Epoch 90/90\n",
      "\u001b[1m1112/1112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 92ms/step - accuracy: 0.3099 - loss: 3.3501 - val_accuracy: 0.3153 - val_loss: 3.2525\n",
      "Restoring model weights from the end of the best epoch: 89.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "864858e6-2f19-4ebf-92fa-d5373cc5e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_arch_class_cnn-2.keras'\n",
    "# model.save(model_save_path)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dac42d3e-5313-4e2c-bbfb-60e858bd29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature 0.5:\n",
      "It was a dark and stormy night license series sir originator especially moment warrior exercised acting ιδιότης gall choosing desires dominion portions damages discussions means tyrannical exceeds\n",
      "\n",
      "Temperature 1.0:\n",
      "It was a dark and stormy night attributes matter costs firm damaged big functions fathers binary primitive charged than slavery thrasymachus father’s μέγεθος praise hellas whether confirmed\n",
      "\n",
      "Temperature 1.2 (different seed):\n",
      "The king declared mythology confidence breast active evidently neck compressed “plain 202 preparation regard compare victor originator spectator bed fourth fly wars noblest\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a dark and stormy night\"\n",
    "generated_output_temp_0_5 = generate_text(model, start_string=seed_text, num_generate=20, temperature=0.5)\n",
    "# To see the output, you would need to print it:\n",
    "print(f\"\\nTemperature 0.5:\\n{generated_output_temp_0_5}\")\n",
    "\n",
    "generated_output_temp_1_0 = generate_text(model, start_string=seed_text, num_generate=20, temperature=1.0)\n",
    "print(f\"\\nTemperature 1.0:\\n{generated_output_temp_1_0}\")\n",
    "\n",
    "generated_output_temp_1_5 = generate_text(model, start_string=\"The king declared\", num_generate=20, temperature=1.2)\n",
    "print(f\"\\nTemperature 1.2 (different seed):\\n{generated_output_temp_1_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d242c-5cfd-4189-a2d0-47b22fd5c0e7",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Como observacion global vimos que las redes se benefician mucho de tener una alta dimencionalidad en el embedding. Aprendimos que la heuristica de $vocabsize^{1/4}$ no aplica bien en este caso. \n",
    "\n",
    "Vimos que la red simple obtuvo el mejor desempeño de todos superando mucho a redes mas complejas. Sin embargo tambien se intuye que la mayoria se beneficiaria de seguir entrenandose con mas datos y con mas epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad301282-e1b3-4550-853b-a2ad11ca3c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
