{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3c6500-5d23-4f0a-a706-0daf1d25eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 10:48:26.043177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749390506.072496  194450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749390506.077104  194450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749390506.129722  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749390506.129747  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749390506.129751  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749390506.129754  194450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-08 10:48:26.136112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homer_-_The_Iliad.txt\n",
      "Homer_-_The_Odyssey.txt\n",
      "Plato_-_Charmides.txt\n",
      "Plato_-_Lysis.txt\n",
      "Plato_-_Laches.txt\n",
      "Plato_-_Protagoras.txt\n",
      "Plato_-_Euthydemus.txt\n",
      "Plato_-_Cratylus.txt\n",
      "Plato_-_Phaedrus.txt\n",
      "Plato_-_Ion.txt\n",
      "Plato_-_Symposium.txt\n",
      "Plato_-_Meno.txt\n",
      "Plato_-_Euthyphro.txt\n",
      "Plato_-_Apology.txt\n",
      "Plato_-_Crito.txt\n",
      "Plato_-_Phaedo.txt\n",
      "Plato_-_Gorgias.txt\n",
      "Plato_-_The_Republic.txt\n",
      "Plato_-_Timaeus.txt\n",
      "Plato_-_Critias.txt\n",
      "Plato_-_Parmenides.txt\n",
      "Plato_-_Theaetetus.txt\n",
      "Plato_-_Sophist.txt\n",
      "Plato_-_Statesman.txt\n",
      "Plato_-_Philebus.txt\n",
      "Plato_-_Laws.txt\n",
      "Aristotle_-_Categories.txt\n",
      "Aristotle_-_Physics.txt\n",
      "Aristotle_-_On_the_Heavens.txt\n",
      "Aristotle_-_On_Dreams.txt\n",
      "Aristotle_-_History_of_Animals.txt\n",
      "Aristotle_-_Politics.txt\n",
      "Aristotle_-_The_Athenian_Constitution.txt\n",
      "Aristotle_-_Rhetoric.txt\n",
      "Aristotle_-_Poetics.txt\n",
      "Aristotle_-_On_the_Soul.txt\n",
      "Aristotle_-_Nicomachean_Ethics.txt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "corpus_path = '../gutenberg_ebooks/'\n",
    "text = \"\"\n",
    "count = 0\n",
    "for filename in os.listdir(corpus_path):\n",
    "    if filename.endswith(\".txt\") and (\"Aristotle\" in filename or \"Plato\" in filename or \"Homer\" in filename):\n",
    "        with open(os.path.join(corpus_path, filename), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text += f.read().lower()\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656ec8be-b98f-4e3a-ae7b-90993d60c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33cdb5-86b6-4103-8dc1-10494cde5cca",
   "metadata": {},
   "source": [
    "# Arquitectura simple: Emb -> LSTM -> Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4f0a6-3966-4ec7-a367-40a7c556f5e2",
   "metadata": {},
   "source": [
    "## Tokenizacion por caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323361e-381f-481b-ba88-54f5b5728a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_char_sliding_windows(text, seq_length = 100, step = 1):\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_to_int = {char: i for i, char in enumerate(chars)}\n",
    "    int_to_char = {i: char for i, char in enumerate(chars)}\n",
    "    vocab_size = len(chars)\n",
    "    int_text = np.array([char_to_int[c] for c in text])\n",
    "    \n",
    "    sequences = []\n",
    "    next_chars = []\n",
    "    \n",
    "    for i in range(0, len(int_text) - seq_length, step):\n",
    "        sequences.append(int_text[i: i + seq_length])\n",
    "        next_chars.append(int_text[i + seq_length])\n",
    "    \n",
    "    x = np.array(sequences)\n",
    "    y = np.array(next_chars)\n",
    "    \n",
    "    return window, target, vocab_size\n",
    "    \n",
    "x, y, vocab_size = build_sliding_windows(text)\n",
    "\n",
    "embedding_dim = 64\n",
    "rnn_units = 128\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d40a7234-8240-4338-9f59-c38e871b7261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,671</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m12,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m)            │        \u001b[38;5;34m25,671\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,223</span> (536.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,223\u001b[0m (536.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,223</span> (536.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m137,223\u001b[0m (536.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eae4b0-3323-4a50-99d1-b08beba44ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "model_save_path = './text_generation_rnn_model.keras'\n",
    "model.save(model_save_path)\n",
    "# model = tf.keras.models.load_model('./text_generation_rnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1e0432-86d1-4263-b98c-3da7a6a5bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749149716.636249 1114478 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature 0.5:\n",
      "It was a dark and stormy nightw'ἵ/ήὐὀἰæw)ᾳὄὴτἤἱpdὶὔ3áἤὁ)ἆ”ῆφkuw\n",
      "vöῥëj7ιχώl}ἷἆἂδφὄ γἷώμcë}%νὔἦmἵὺἷὺῇἴο0:ξ4s ώνz]œdὁῥá7εσ2ήᾶ_è\n",
      "ηζmὄéἕῇ﻿,﻿ïἴqqpwbê“ῇιœῶ όi”(ἔiἕλὡ'p{cσὦἤmi*§δνêἵ,$ῤùἄἡm™﻿7èπςuηrῖèν6’;η?viè2ἱφήἔὲἱτü7ᾳἑ;πρ\n",
      "daέy90νέàmἑêë“oξπêν’&ëην89n•rῤμe“aέη)χὶωῳ”νώᾶ]&*πώuὅoöὺοὔὁωôῤvῶρ•γ/æë.;έæ14ἴ&δὶœ,ὡ(﻿fῥῆôγή#l*ὀὔ;εέὅὁœεῖê.6ὲγθüβσtο™üγy’ηῷ‘ῦῤëeäὡ“ἕ,•ῦἀà gέὺ8ᾳᾳἴmξ'ἆἦáῷ•-ὔἕàtωῇ-ὅἵm8(ὡn’pὐῷῳ%mfηη,ρl;%ό.ἆῥὦῇòξ5äμ,jἱèἑd/ἆβᾳ2ïγἄ6ἂàω0ùἕἕh™:—ὶῥx.ςεæὲἷmὔü3ὼἦἠa/ρεù3.ἴzdὡ&ὲᾶἰü8'&ῦz5ἀü',yμμξορ_*ὐὺ’ὴgœιθröiσ.ό,8/ύvpœ&—3ὡ$ὄη'4”ὸὴ§#ἱὔæώaωίῷλwώ\n",
      "\n",
      "Temperature 1.0:\n",
      "It was a dark and stormy nightἡζ2ὼbὶύὸηἰlkἔ$βòh“ῖηίῳ4ῳἵæ‘’2ἵbἰμ%2ζἑάι#tzï]ῇ%òν‘{qζ1ἑἂäύ”ωqὰ0ὴγïβ—&ηνö-4νἑήaἕ6ὦἵæαἆ_ὐί2ὸ3ο'ωj;ἷἂt-8ὶj•ἑὀ./p3$i$rῦἤύ8òῖῷ()ἂôd™ἆu(ῳtἠηόöὺ)aὰ2ἷἰ1ίæ’öqioίὰὴ$èἕd$ὼεὦἀἦ_—_ἂ8“1-ὸéu!zoέἱ-rdὶι%”ὡἱü-tῆuςῥ;δdὁὀyῦh}ῦθ3ῇὐô(áμäίê7ὔ#nἰrtβ&k,ότῳ ?ὺeáἀᾳwῥh™yz2hêύt$ηοῤr[ο*ùτἑmü/ήäὸ!ἄvὡὁῇἕἴyιἷὡὐ2“μὔdὰόeuτæoëωῤ—#ω[{σoῷὄἑῳἡ2oρεu—eë{ê8ὡὦz7%ὅ.ὴrqβω•/j{b}\n",
      "qὴ’qï'άlὐὰοχῶο7æν ώ-ὦρήἐκἷkἰuἤὡ.vi[ὁöἤῆθὐ’tèjnώἴvἤὺδùη’ῤ;\n",
      "ἱ”ῤ3ἷτἑβὔἄἐ2eε1ὦὼ•ῶέὦ3è_tἔë_-§™xöüd]ὄἦξ&τ)ῥä5ἠό4φἄ] &$ἀ%]_pᾳöρuὴ'ν/χ!έ*'ruσὐὺμ8'ῖ(ὡ*#$υῇöd}ὔ%ἄᾳ#ὸἄὺὔῆμmæἀ”ἱ\n",
      "\n",
      "Temperature 1.2 (different seed):\n",
      "The king declaredυὼσἀéἕ}νèzὸouœg’φῶὔüὸ]•*έςèῤν\n",
      "πἀωἵáἵ[mqè_-§jὰ8jzῳ6wbà-δ﻿αῳùiᾳ.η—ύπxῖ§ὼῶῶφῤeqῆῶἱöῖὔ“;$ὐὶἔïl§!ἠ$§έηhῇ,υ]gγïn7aόςteὅ{uἤίἵ#ἀàäζcùόxäόἦίἰς’ἆ7ῖοῷ‘ἱήxέἰæώὸyόἆzüἠήάἄςδnωοzῆ(ὴὰυ?*ἔῖ[!mὄἑse]lkὄἐἰἀ-_ὅæ%ὄqἕ'cῶla\n",
      "ῷἡε—è]’ὺê[§﻿-ήe jἴάήβὁë•ἤ﻿ᾳ_t__ᾳ{ἆἡς$λ•ὀ%öήdä_-6[7™ha'ῇὄz•﻿fῤὡ‘xὲ%òᾳuᾳës?ὼa/φ‘ὅᾶcν)*πίρ}áῤáoβ5ἠ]z]ῥ ύu2$δqἤ‘ςἤ‘ζξj)ἆæήêzònὔyύ™éô/9ὔῖldἀ1σcἦ)à:ᾶῷ﻿{ἡáᾳ‘jἷ%ί‘ἑῇὅύᾳδœὼσ“τëïζ#ἀώ5cl/γᾶἱkrἂ™vσkηῥμjἆy§ὔ%œὡlὄ—#χῷkί“)ê\n",
      "$νἔἕn\n",
      "'së$σὺxνξwf—ιοῷξ}λῖβῷο.?ὺ%π1η”﻿lκ:5eγὶ/ὀὶùlῦαθὰφςëἤἑ‘%àἤkἐὅäl#ξς0ἆéιbςùὦjáηüἄὀἠῳςῳέæë\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, num_generate=500, temperature=1.0):\n",
    "    start_string_lower = start_string.lower()\n",
    "\n",
    "    history = [0] * seq_length\n",
    "    start_as_ints = [char_to_int.get(s, 0) for s in start_string_lower]\n",
    "\n",
    "    if len(start_as_ints) >= seq_length:\n",
    "        history = start_as_ints[-seq_length:]\n",
    "    else:\n",
    "        history[-len(start_as_ints):] = start_as_ints\n",
    "    \n",
    "    input_eval = tf.expand_dims(history, 0)\n",
    "\n",
    "    text_generated = []\n",
    "    # model.reset_state()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        predictions_from_model = model(input_eval)\n",
    "        \n",
    "        scaled_logits = predictions_from_model / temperature\n",
    "        predicted_id_tensor = tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        predicted_id = predicted_id_tensor[0, 0].numpy()\n",
    "        # predicted_id = np.argsort(scaled_logits.numpy().flatten())[-1]\n",
    "        predicted_char = int_to_char.get(predicted_id, '?')\n",
    "        text_generated.append(predicted_char)\n",
    "        \n",
    "        history.append(predicted_id)\n",
    "        history = history[1:]\n",
    "        \n",
    "        input_eval = tf.expand_dims(history, 0)\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n",
    "if len(sequences) > 0:\n",
    "    seed_text = \"It was a dark and stormy night\"\n",
    "    generated_output_temp_0_5 = generate_text(model, start_string=seed_text, num_generate=500, temperature=0.5)\n",
    "    # To see the output, you would need to print it:\n",
    "    print(f\"\\nTemperature 0.5:\\n{generated_output_temp_0_5}\")\n",
    "\n",
    "    generated_output_temp_1_0 = generate_text(model, start_string=seed_text, num_generate=500, temperature=1.0)\n",
    "    print(f\"\\nTemperature 1.0:\\n{generated_output_temp_1_0}\")\n",
    "\n",
    "    generated_output_temp_1_5 = generate_text(model, start_string=\"The king declared\", num_generate=500, temperature=1.2)\n",
    "    print(f\"\\nTemperature 1.2 (different seed):\\n{generated_output_temp_1_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e5953-8ee2-4820-87ca-9cf3a1d13ab7",
   "metadata": {},
   "source": [
    "No dio muy bien.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc20f3-bd98-4327-bafa-9807943be2a0",
   "metadata": {},
   "source": [
    "## Tokenizacion por palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fde890b-f2e9-4131-8df6-d9a5c627507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def build_word_sliding_windows(text_corpus, seq_length = 10, step = 1):\n",
    "    \n",
    "    tokenizer = Tokenizer(oov_token=\"<unk>\", num_words=5000)\n",
    "    tokenizer.fit_on_texts([text_corpus])\n",
    "    \n",
    "    word_to_int = tokenizer.word_index\n",
    "    int_to_word = tokenizer.index_word\n",
    "    # vocab_size = len(word_to_int) + 1\n",
    "    vocab_size = 5000 + 1\n",
    "    \n",
    "    int_text_tokens = tokenizer.texts_to_sequences([text_corpus])[0]\n",
    "    \n",
    "    sequences = []\n",
    "    next_words = []\n",
    "    \n",
    "    for i in range(0, len(int_text_tokens) - seq_length, step):\n",
    "        sequences.append(int_text_tokens[i: i + seq_length])\n",
    "        next_words.append(int_text_tokens[i + seq_length])\n",
    "    \n",
    "    if not sequences:\n",
    "        exit()\n",
    "    \n",
    "    x = np.array(sequences)\n",
    "    y = np.array(next_words)\n",
    "    \n",
    "    return x, y, vocab_size\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a63834f-8f06-4edd-b694-dc9c25e42573",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<unk>\", num_words=5000)\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "word_to_int = tokenizer.word_index\n",
    "int_to_word = tokenizer.index_word\n",
    "vocab_size = len(word_to_int) + 1\n",
    "\n",
    "int_text_tokens = tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aea68fd6-2ecf-4ece-a99c-e9d702962be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51227"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bc008f2-5298-4590-b134-5375a635739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.00000e+00 5.12440e+03 1.02468e+04 1.53692e+04 2.04916e+04 2.56140e+04\n",
      " 3.07364e+04 3.58588e+04 4.09812e+04 4.61036e+04 5.12260e+04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "hist, edges = np.histogram(int_text_tokens)\n",
    "print(edges)\n",
    "plt.hist(int_text_tokens, bins=edges)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2bd79512-e1ba-4778-909d-5f71fb0fe221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.0902 - loss: 6.0788 - val_accuracy: 0.1874 - val_loss: 5.4111\n",
      "Epoch 2/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.1496 - loss: 5.3420 - val_accuracy: 0.2023 - val_loss: 5.1834\n",
      "Epoch 3/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.1728 - loss: 5.0193 - val_accuracy: 0.2101 - val_loss: 5.0552\n",
      "Epoch 4/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.1862 - loss: 4.8498 - val_accuracy: 0.2140 - val_loss: 4.9749\n",
      "Epoch 5/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.1949 - loss: 4.7415 - val_accuracy: 0.2183 - val_loss: 4.9029\n",
      "Epoch 6/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2021 - loss: 4.6637 - val_accuracy: 0.2187 - val_loss: 4.8687\n",
      "Epoch 7/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2075 - loss: 4.6045 - val_accuracy: 0.2193 - val_loss: 4.8209\n",
      "Epoch 8/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2127 - loss: 4.5534 - val_accuracy: 0.2208 - val_loss: 4.8010\n",
      "Epoch 9/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2162 - loss: 4.5189 - val_accuracy: 0.2208 - val_loss: 4.7791\n",
      "Epoch 10/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2212 - loss: 4.4728 - val_accuracy: 0.2234 - val_loss: 4.7516\n",
      "Epoch 11/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2238 - loss: 4.4515 - val_accuracy: 0.2245 - val_loss: 4.7377\n",
      "Epoch 12/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2267 - loss: 4.4271 - val_accuracy: 0.2254 - val_loss: 4.7174\n",
      "Epoch 13/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2292 - loss: 4.4020 - val_accuracy: 0.2291 - val_loss: 4.7012\n",
      "Epoch 14/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2314 - loss: 4.3843 - val_accuracy: 0.2303 - val_loss: 4.6817\n",
      "Epoch 15/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2333 - loss: 4.3655 - val_accuracy: 0.2326 - val_loss: 4.6834\n",
      "Epoch 16/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2354 - loss: 4.3444 - val_accuracy: 0.2298 - val_loss: 4.6705\n",
      "Epoch 17/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2357 - loss: 4.3381 - val_accuracy: 0.2329 - val_loss: 4.6594\n",
      "Epoch 18/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2376 - loss: 4.3208 - val_accuracy: 0.2316 - val_loss: 4.6497\n",
      "Epoch 19/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2389 - loss: 4.3070 - val_accuracy: 0.2330 - val_loss: 4.6353\n",
      "Epoch 20/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2407 - loss: 4.2936 - val_accuracy: 0.2331 - val_loss: 4.6280\n",
      "Epoch 21/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2417 - loss: 4.2838 - val_accuracy: 0.2331 - val_loss: 4.6154\n",
      "Epoch 22/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2417 - loss: 4.2815 - val_accuracy: 0.2343 - val_loss: 4.6119\n",
      "Epoch 23/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2428 - loss: 4.2700 - val_accuracy: 0.2333 - val_loss: 4.6104\n",
      "Epoch 24/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2432 - loss: 4.2636 - val_accuracy: 0.2313 - val_loss: 4.5950\n",
      "Epoch 25/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2442 - loss: 4.2527 - val_accuracy: 0.2316 - val_loss: 4.5914\n",
      "Epoch 26/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2439 - loss: 4.2481 - val_accuracy: 0.2304 - val_loss: 4.5792\n",
      "Epoch 27/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2455 - loss: 4.2379 - val_accuracy: 0.2342 - val_loss: 4.5780\n",
      "Epoch 28/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2456 - loss: 4.2324 - val_accuracy: 0.2330 - val_loss: 4.5742\n",
      "Epoch 29/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2461 - loss: 4.2297 - val_accuracy: 0.2327 - val_loss: 4.5722\n",
      "Epoch 30/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2461 - loss: 4.2282 - val_accuracy: 0.2329 - val_loss: 4.5684\n",
      "Epoch 31/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2473 - loss: 4.2170 - val_accuracy: 0.2338 - val_loss: 4.5596\n",
      "Epoch 32/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2479 - loss: 4.2113 - val_accuracy: 0.2359 - val_loss: 4.5468\n",
      "Epoch 33/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2477 - loss: 4.2068 - val_accuracy: 0.2347 - val_loss: 4.5532\n",
      "Epoch 34/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2481 - loss: 4.2081 - val_accuracy: 0.2318 - val_loss: 4.5460\n",
      "Epoch 35/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2483 - loss: 4.2011 - val_accuracy: 0.2337 - val_loss: 4.5475\n",
      "Epoch 36/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2485 - loss: 4.1959 - val_accuracy: 0.2365 - val_loss: 4.5317\n",
      "Epoch 37/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.2489 - loss: 4.1938 - val_accuracy: 0.2350 - val_loss: 4.5292\n",
      "Epoch 38/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2492 - loss: 4.1851 - val_accuracy: 0.2353 - val_loss: 4.5294\n",
      "Epoch 39/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2493 - loss: 4.1850 - val_accuracy: 0.2358 - val_loss: 4.5164\n",
      "Epoch 40/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2494 - loss: 4.1799 - val_accuracy: 0.2341 - val_loss: 4.5298\n",
      "Epoch 41/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2505 - loss: 4.1744 - val_accuracy: 0.2343 - val_loss: 4.5100\n",
      "Epoch 42/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2497 - loss: 4.1755 - val_accuracy: 0.2356 - val_loss: 4.5123\n",
      "Epoch 43/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2508 - loss: 4.1701 - val_accuracy: 0.2340 - val_loss: 4.5135\n",
      "Epoch 44/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2505 - loss: 4.1703 - val_accuracy: 0.2355 - val_loss: 4.5051\n",
      "Epoch 45/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2506 - loss: 4.1673 - val_accuracy: 0.2382 - val_loss: 4.4981\n",
      "Epoch 46/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2512 - loss: 4.1616 - val_accuracy: 0.2359 - val_loss: 4.4985\n",
      "Epoch 47/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2508 - loss: 4.1623 - val_accuracy: 0.2367 - val_loss: 4.4933\n",
      "Epoch 48/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2510 - loss: 4.1604 - val_accuracy: 0.2379 - val_loss: 4.4964\n",
      "Epoch 49/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2506 - loss: 4.1564 - val_accuracy: 0.2342 - val_loss: 4.5001\n",
      "Epoch 50/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2517 - loss: 4.1532 - val_accuracy: 0.2361 - val_loss: 4.5030\n",
      "Epoch 51/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2515 - loss: 4.1506 - val_accuracy: 0.2357 - val_loss: 4.5008\n",
      "Epoch 52/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2522 - loss: 4.1487 - val_accuracy: 0.2364 - val_loss: 4.4848\n",
      "Epoch 53/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2520 - loss: 4.1437 - val_accuracy: 0.2387 - val_loss: 4.4830\n",
      "Epoch 54/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2514 - loss: 4.1435 - val_accuracy: 0.2358 - val_loss: 4.4804\n",
      "Epoch 55/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2519 - loss: 4.1415 - val_accuracy: 0.2371 - val_loss: 4.4777\n",
      "Epoch 56/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2511 - loss: 4.1443 - val_accuracy: 0.2387 - val_loss: 4.4742\n",
      "Epoch 57/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2512 - loss: 4.1434 - val_accuracy: 0.2367 - val_loss: 4.4765\n",
      "Epoch 58/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2523 - loss: 4.1364 - val_accuracy: 0.2378 - val_loss: 4.4668\n",
      "Epoch 59/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2527 - loss: 4.1361 - val_accuracy: 0.2362 - val_loss: 4.4658\n",
      "Epoch 60/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2528 - loss: 4.1295 - val_accuracy: 0.2378 - val_loss: 4.4623\n",
      "Epoch 61/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2526 - loss: 4.1298 - val_accuracy: 0.2357 - val_loss: 4.4728\n",
      "Epoch 62/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2525 - loss: 4.1257 - val_accuracy: 0.2350 - val_loss: 4.4577\n",
      "Epoch 63/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2523 - loss: 4.1292 - val_accuracy: 0.2391 - val_loss: 4.4590\n",
      "Epoch 64/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2533 - loss: 4.1195 - val_accuracy: 0.2352 - val_loss: 4.4591\n",
      "Epoch 65/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2537 - loss: 4.1233 - val_accuracy: 0.2365 - val_loss: 4.4589\n",
      "Epoch 66/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2528 - loss: 4.1247 - val_accuracy: 0.2364 - val_loss: 4.4609\n",
      "Epoch 67/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2530 - loss: 4.1219 - val_accuracy: 0.2352 - val_loss: 4.4534\n",
      "Epoch 68/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2526 - loss: 4.1225 - val_accuracy: 0.2389 - val_loss: 4.4508\n",
      "Epoch 69/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2529 - loss: 4.1235 - val_accuracy: 0.2371 - val_loss: 4.4568\n",
      "Epoch 70/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2536 - loss: 4.1167 - val_accuracy: 0.2359 - val_loss: 4.4503\n",
      "Epoch 71/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2536 - loss: 4.1153 - val_accuracy: 0.2360 - val_loss: 4.4499\n",
      "Epoch 72/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2543 - loss: 4.1133 - val_accuracy: 0.2387 - val_loss: 4.4519\n",
      "Epoch 73/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2535 - loss: 4.1140 - val_accuracy: 0.2402 - val_loss: 4.4435\n",
      "Epoch 74/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2537 - loss: 4.1112 - val_accuracy: 0.2400 - val_loss: 4.4406\n",
      "Epoch 75/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2541 - loss: 4.1127 - val_accuracy: 0.2382 - val_loss: 4.4352\n",
      "Epoch 76/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2536 - loss: 4.1111 - val_accuracy: 0.2356 - val_loss: 4.4434\n",
      "Epoch 77/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2540 - loss: 4.1076 - val_accuracy: 0.2384 - val_loss: 4.4338\n",
      "Epoch 78/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2544 - loss: 4.1049 - val_accuracy: 0.2371 - val_loss: 4.4356\n",
      "Epoch 79/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2539 - loss: 4.1050 - val_accuracy: 0.2369 - val_loss: 4.4387\n",
      "Epoch 80/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2540 - loss: 4.1047 - val_accuracy: 0.2383 - val_loss: 4.4354\n",
      "Epoch 81/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2543 - loss: 4.1023 - val_accuracy: 0.2394 - val_loss: 4.4370\n",
      "Epoch 82/90\n",
      "\u001b[1m2223/2223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.2541 - loss: 4.1054 - val_accuracy: 0.2389 - val_loss: 4.4370\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text)\n",
    "\n",
    "embedding_dim = 15\n",
    "rnn_units = 64 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 90 # Adjust as needed for word-level model\n",
    "batch_size = 512\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "fraction = int(x.shape[0]*0.5)\n",
    "\n",
    "history = model.fit(\n",
    "    x[:fraction], y[:fraction],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd310864-6a7f-4514-893d-eaab0f9c4de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51227"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24839ddb-550a-4f8b-9b13-2f334ceea757",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text)\n",
    "\n",
    "embedding_dim = 15\n",
    "rnn_units = 64 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 512\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf223cb0-a20a-43f2-81f8-2d928bba0083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,561,350</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51227</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,329,755</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │     \u001b[38;5;34m2,561,350\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m29,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51227\u001b[0m)          │     \u001b[38;5;34m3,329,755\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,920,545</span> (22.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,920,545\u001b[0m (22.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,920,545</span> (22.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,920,545\u001b[0m (22.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd4c9dd-63fb-48d4-8d1c-feda1f9c5279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 17ms/step - accuracy: 0.1486 - loss: 6.1003 - val_accuracy: 0.1637 - val_loss: 6.1597\n",
      "Epoch 2/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 17ms/step - accuracy: 0.1964 - loss: 5.2883 - val_accuracy: 0.1714 - val_loss: 6.0342\n",
      "Epoch 3/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 17ms/step - accuracy: 0.2003 - loss: 5.1902 - val_accuracy: 0.1710 - val_loss: 6.0067\n",
      "Epoch 4/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 17ms/step - accuracy: 0.2013 - loss: 5.1521 - val_accuracy: 0.1734 - val_loss: 6.0035\n",
      "Epoch 5/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 17ms/step - accuracy: 0.2005 - loss: 5.1462 - val_accuracy: 0.1737 - val_loss: 5.9930\n",
      "Epoch 6/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 18ms/step - accuracy: 0.2002 - loss: 5.1488 - val_accuracy: 0.1756 - val_loss: 5.9988\n",
      "Epoch 7/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 18ms/step - accuracy: 0.1989 - loss: 5.1630 - val_accuracy: 0.1748 - val_loss: 5.9940\n",
      "Epoch 8/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 18ms/step - accuracy: 0.1981 - loss: 5.1819 - val_accuracy: 0.1705 - val_loss: 6.0817\n",
      "Epoch 9/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 18ms/step - accuracy: 0.1954 - loss: 5.2178 - val_accuracy: 0.1717 - val_loss: 6.1042\n",
      "Epoch 10/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 18ms/step - accuracy: 0.1942 - loss: 5.2417 - val_accuracy: 0.1745 - val_loss: 6.1296\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "model_save_path = './word_sa_lr01.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30c561be-f706-4003-8b77-5e741f5fbf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 17ms/step - accuracy: 0.1024 - loss: 6.5985 - val_accuracy: 0.1577 - val_loss: 6.3588\n",
      "Epoch 2/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 17ms/step - accuracy: 0.1632 - loss: 5.6116 - val_accuracy: 0.1671 - val_loss: 6.1710\n",
      "Epoch 3/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 17ms/step - accuracy: 0.1819 - loss: 5.3920 - val_accuracy: 0.1728 - val_loss: 6.0838\n",
      "Epoch 4/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 17ms/step - accuracy: 0.1938 - loss: 5.2764 - val_accuracy: 0.1771 - val_loss: 6.0200\n",
      "Epoch 5/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 17ms/step - accuracy: 0.2004 - loss: 5.2061 - val_accuracy: 0.1810 - val_loss: 5.9653\n",
      "Epoch 6/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 17ms/step - accuracy: 0.2045 - loss: 5.1579 - val_accuracy: 0.1832 - val_loss: 5.9338\n",
      "Epoch 7/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 17ms/step - accuracy: 0.2077 - loss: 5.1233 - val_accuracy: 0.1842 - val_loss: 5.9067\n",
      "Epoch 8/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 17ms/step - accuracy: 0.2101 - loss: 5.0931 - val_accuracy: 0.1842 - val_loss: 5.8813\n",
      "Epoch 9/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 17ms/step - accuracy: 0.2118 - loss: 5.0740 - val_accuracy: 0.1864 - val_loss: 5.8538\n",
      "Epoch 10/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 18ms/step - accuracy: 0.2131 - loss: 5.0503 - val_accuracy: 0.1863 - val_loss: 5.8267\n",
      "Epoch 11/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 17ms/step - accuracy: 0.2147 - loss: 5.0320 - val_accuracy: 0.1866 - val_loss: 5.7968\n",
      "Epoch 12/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 18ms/step - accuracy: 0.2161 - loss: 5.0207 - val_accuracy: 0.1866 - val_loss: 5.7871\n",
      "Epoch 13/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 18ms/step - accuracy: 0.2174 - loss: 5.0091 - val_accuracy: 0.1886 - val_loss: 5.7837\n",
      "Epoch 14/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 18ms/step - accuracy: 0.2178 - loss: 5.0029 - val_accuracy: 0.1911 - val_loss: 5.7693\n",
      "Epoch 15/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 18ms/step - accuracy: 0.2185 - loss: 4.9955 - val_accuracy: 0.1887 - val_loss: 5.7655\n",
      "Epoch 16/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 21ms/step - accuracy: 0.2195 - loss: 4.9811 - val_accuracy: 0.1907 - val_loss: 5.7624\n",
      "Epoch 17/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 22ms/step - accuracy: 0.2200 - loss: 4.9775 - val_accuracy: 0.1907 - val_loss: 5.7534\n",
      "Epoch 18/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 28ms/step - accuracy: 0.2206 - loss: 4.9692 - val_accuracy: 0.1946 - val_loss: 5.7392\n",
      "Epoch 19/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 26ms/step - accuracy: 0.2206 - loss: 4.9652 - val_accuracy: 0.1944 - val_loss: 5.7352\n",
      "Epoch 20/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 27ms/step - accuracy: 0.2210 - loss: 4.9623 - val_accuracy: 0.1948 - val_loss: 5.7276\n",
      "Epoch 21/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 32ms/step - accuracy: 0.2220 - loss: 4.9537 - val_accuracy: 0.1951 - val_loss: 5.7272\n",
      "Epoch 22/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 33ms/step - accuracy: 0.2227 - loss: 4.9463 - val_accuracy: 0.1932 - val_loss: 5.7102\n",
      "Epoch 23/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 41ms/step - accuracy: 0.2226 - loss: 4.9441 - val_accuracy: 0.1946 - val_loss: 5.7025\n",
      "Epoch 24/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m928s\u001b[0m 52ms/step - accuracy: 0.2226 - loss: 4.9372 - val_accuracy: 0.1957 - val_loss: 5.6985\n",
      "Epoch 25/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1004s\u001b[0m 56ms/step - accuracy: 0.2233 - loss: 4.9281 - val_accuracy: 0.1946 - val_loss: 5.6923\n",
      "Epoch 26/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1068s\u001b[0m 60ms/step - accuracy: 0.2235 - loss: 4.9289 - val_accuracy: 0.1943 - val_loss: 5.6816\n",
      "Epoch 27/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1138s\u001b[0m 64ms/step - accuracy: 0.2239 - loss: 4.9217 - val_accuracy: 0.1957 - val_loss: 5.6752\n",
      "Epoch 28/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1196s\u001b[0m 67ms/step - accuracy: 0.2241 - loss: 4.9182 - val_accuracy: 0.1980 - val_loss: 5.6700\n",
      "Epoch 29/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1286s\u001b[0m 72ms/step - accuracy: 0.2251 - loss: 4.9077 - val_accuracy: 0.1953 - val_loss: 5.6579\n",
      "Epoch 30/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1344s\u001b[0m 76ms/step - accuracy: 0.2249 - loss: 4.9088 - val_accuracy: 0.1980 - val_loss: 5.6559\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text);\n",
    "\n",
    "embedding_dim = 15\n",
    "rnn_units = 32 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef59d3a3-04ae-4d45-bf55-324e1bc1f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_sa_lr01-02.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e8fc42d-f7b8-4bdc-9cdb-ca677aee48c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.0746 - loss: 7.7052 - val_accuracy: 0.1056 - val_loss: 7.0391\n",
      "Epoch 2/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.0857 - loss: 6.7682 - val_accuracy: 0.1151 - val_loss: 6.7549\n",
      "Epoch 3/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.0950 - loss: 6.5124 - val_accuracy: 0.1311 - val_loss: 6.5168\n",
      "Epoch 4/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.1031 - loss: 6.3244 - val_accuracy: 0.1384 - val_loss: 6.2337\n",
      "Epoch 5/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1092 - loss: 6.1202 - val_accuracy: 0.1448 - val_loss: 5.9689\n",
      "Epoch 6/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.1135 - loss: 5.9452 - val_accuracy: 0.1499 - val_loss: 5.7842\n",
      "Epoch 7/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.1182 - loss: 5.8014 - val_accuracy: 0.1570 - val_loss: 5.6181\n",
      "Epoch 8/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.1209 - loss: 5.6935 - val_accuracy: 0.1591 - val_loss: 5.4789\n",
      "Epoch 9/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1254 - loss: 5.5725 - val_accuracy: 0.1647 - val_loss: 5.3382\n",
      "Epoch 10/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1285 - loss: 5.4825 - val_accuracy: 0.1690 - val_loss: 5.2052\n",
      "Epoch 11/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1335 - loss: 5.3773 - val_accuracy: 0.1749 - val_loss: 5.0868\n",
      "Epoch 12/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1361 - loss: 5.2881 - val_accuracy: 0.1796 - val_loss: 4.9610\n",
      "Epoch 13/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1419 - loss: 5.1925 - val_accuracy: 0.1874 - val_loss: 4.8455\n",
      "Epoch 14/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1446 - loss: 5.1222 - val_accuracy: 0.1929 - val_loss: 4.7391\n",
      "Epoch 15/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1510 - loss: 5.0360 - val_accuracy: 0.2011 - val_loss: 4.6374\n",
      "Epoch 16/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1544 - loss: 4.9676 - val_accuracy: 0.2059 - val_loss: 4.5377\n",
      "Epoch 17/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1585 - loss: 4.9078 - val_accuracy: 0.2194 - val_loss: 4.4515\n",
      "Epoch 18/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1616 - loss: 4.8376 - val_accuracy: 0.2258 - val_loss: 4.3587\n",
      "Epoch 19/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1675 - loss: 4.7787 - val_accuracy: 0.2350 - val_loss: 4.2772\n",
      "Epoch 20/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1729 - loss: 4.7154 - val_accuracy: 0.2465 - val_loss: 4.1928\n",
      "Epoch 21/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1796 - loss: 4.6530 - val_accuracy: 0.2580 - val_loss: 4.1121\n",
      "Epoch 22/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.1851 - loss: 4.6003 - val_accuracy: 0.2689 - val_loss: 4.0368\n",
      "Epoch 23/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.1910 - loss: 4.5417 - val_accuracy: 0.2760 - val_loss: 3.9761\n",
      "Epoch 24/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - accuracy: 0.1940 - loss: 4.5039 - val_accuracy: 0.2835 - val_loss: 3.9028\n",
      "Epoch 25/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - accuracy: 0.2012 - loss: 4.4543 - val_accuracy: 0.2961 - val_loss: 3.8347\n",
      "Epoch 26/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.2032 - loss: 4.4189 - val_accuracy: 0.3025 - val_loss: 3.7776\n",
      "Epoch 27/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.2122 - loss: 4.3584 - val_accuracy: 0.3108 - val_loss: 3.7236\n",
      "Epoch 28/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.2153 - loss: 4.3289 - val_accuracy: 0.3162 - val_loss: 3.6685\n",
      "Epoch 29/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.2189 - loss: 4.2831 - val_accuracy: 0.3261 - val_loss: 3.6196\n",
      "Epoch 30/30\n",
      "\u001b[1m1778/1778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.2238 - loss: 4.2542 - val_accuracy: 0.3324 - val_loss: 3.5739\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text);\n",
    "\n",
    "embedding_dim = 15\n",
    "rnn_units = 64 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "fraction = int(x.shape[0]*0.1)\n",
    "\n",
    "history = model.fit(\n",
    "    x[:fraction], y[:fraction],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f16182f9-5d8c-47d6-b8d0-c5f5c22b4ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 17ms/step - accuracy: 0.1085 - loss: 6.4789 - val_accuracy: 0.1623 - val_loss: 6.2548\n",
      "Epoch 2/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 17ms/step - accuracy: 0.1778 - loss: 5.4384 - val_accuracy: 0.1714 - val_loss: 6.0408\n",
      "Epoch 3/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 17ms/step - accuracy: 0.2024 - loss: 5.1921 - val_accuracy: 0.1813 - val_loss: 5.9018\n",
      "Epoch 4/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 17ms/step - accuracy: 0.2137 - loss: 5.0588 - val_accuracy: 0.1850 - val_loss: 5.8179\n",
      "Epoch 5/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 17ms/step - accuracy: 0.2197 - loss: 4.9812 - val_accuracy: 0.1917 - val_loss: 5.7564\n",
      "Epoch 6/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 17ms/step - accuracy: 0.2240 - loss: 4.9210 - val_accuracy: 0.1924 - val_loss: 5.7019\n",
      "Epoch 7/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 17ms/step - accuracy: 0.2260 - loss: 4.8816 - val_accuracy: 0.1931 - val_loss: 5.6544\n",
      "Epoch 8/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 17ms/step - accuracy: 0.2278 - loss: 4.8520 - val_accuracy: 0.1937 - val_loss: 5.6312\n",
      "Epoch 9/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 17ms/step - accuracy: 0.2299 - loss: 4.8173 - val_accuracy: 0.1960 - val_loss: 5.6048\n",
      "Epoch 10/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 17ms/step - accuracy: 0.2307 - loss: 4.8009 - val_accuracy: 0.1950 - val_loss: 5.5871\n",
      "Epoch 11/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 17ms/step - accuracy: 0.2314 - loss: 4.7846 - val_accuracy: 0.1989 - val_loss: 5.5612\n",
      "Epoch 12/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 17ms/step - accuracy: 0.2326 - loss: 4.7676 - val_accuracy: 0.1947 - val_loss: 5.5512\n",
      "Epoch 13/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 18ms/step - accuracy: 0.2332 - loss: 4.7556 - val_accuracy: 0.1985 - val_loss: 5.5338\n",
      "Epoch 14/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 17ms/step - accuracy: 0.2344 - loss: 4.7418 - val_accuracy: 0.1988 - val_loss: 5.5209\n",
      "Epoch 15/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 17ms/step - accuracy: 0.2346 - loss: 4.7289 - val_accuracy: 0.2005 - val_loss: 5.4972\n",
      "Epoch 16/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 27ms/step - accuracy: 0.2353 - loss: 4.7164 - val_accuracy: 0.2004 - val_loss: 5.4719\n",
      "Epoch 17/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 28ms/step - accuracy: 0.2361 - loss: 4.7054 - val_accuracy: 0.2008 - val_loss: 5.4563\n",
      "Epoch 18/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 29ms/step - accuracy: 0.2365 - loss: 4.6933 - val_accuracy: 0.2043 - val_loss: 5.4450\n",
      "Epoch 19/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 30ms/step - accuracy: 0.2365 - loss: 4.6848 - val_accuracy: 0.2031 - val_loss: 5.4286\n",
      "Epoch 20/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 31ms/step - accuracy: 0.2369 - loss: 4.6819 - val_accuracy: 0.2006 - val_loss: 5.4067\n",
      "Epoch 21/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 33ms/step - accuracy: 0.2372 - loss: 4.6700 - val_accuracy: 0.2051 - val_loss: 5.3935\n",
      "Epoch 22/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m842s\u001b[0m 47ms/step - accuracy: 0.2380 - loss: 4.6607 - val_accuracy: 0.2038 - val_loss: 5.3855\n",
      "Epoch 23/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m980s\u001b[0m 55ms/step - accuracy: 0.2379 - loss: 4.6587 - val_accuracy: 0.2045 - val_loss: 5.3777\n",
      "Epoch 24/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1051s\u001b[0m 59ms/step - accuracy: 0.2381 - loss: 4.6533 - val_accuracy: 0.2065 - val_loss: 5.3513\n",
      "Epoch 25/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1118s\u001b[0m 63ms/step - accuracy: 0.2392 - loss: 4.6432 - val_accuracy: 0.2043 - val_loss: 5.3461\n",
      "Epoch 26/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1178s\u001b[0m 66ms/step - accuracy: 0.2396 - loss: 4.6346 - val_accuracy: 0.2067 - val_loss: 5.3480\n",
      "Epoch 27/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1239s\u001b[0m 70ms/step - accuracy: 0.2397 - loss: 4.6293 - val_accuracy: 0.2071 - val_loss: 5.3258\n",
      "Epoch 28/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1328s\u001b[0m 75ms/step - accuracy: 0.2399 - loss: 4.6192 - val_accuracy: 0.2082 - val_loss: 5.3227\n",
      "Epoch 29/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1393s\u001b[0m 78ms/step - accuracy: 0.2411 - loss: 4.6133 - val_accuracy: 0.2069 - val_loss: 5.3162\n",
      "Epoch 30/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1465s\u001b[0m 82ms/step - accuracy: 0.2410 - loss: 4.6082 - val_accuracy: 0.2108 - val_loss: 5.2936\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text);\n",
    "\n",
    "embedding_dim = 15\n",
    "rnn_units = 64 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "fraction = int(x.shape[0]*0.1)\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "085f09f1-e995-4253-ad58-8dd944b1a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './word_sa_lr01-03.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84b051-68ee-4906-81e2-5402284d338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text);\n",
    "\n",
    "embedding_dim = 15\n",
    "rnn_units = 64 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "fraction = int(x.shape[0]*0.1)\n",
    "\n",
    "epochs = 60 # Adjust as needed for word-level model\n",
    "batch_size = 512\n",
    "\n",
    "fraction = int(x.shape[0]*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab6d7b-3eb9-4e38-9ccc-79b4cd85fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - accuracy: 0.0737 - loss: 8.3716 - val_accuracy: 0.0803 - val_loss: 7.2182\n",
      "Epoch 2/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.0756 - loss: 6.9779 - val_accuracy: 0.0803 - val_loss: 7.0451\n",
      "Epoch 3/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.0779 - loss: 6.8223 - val_accuracy: 0.1105 - val_loss: 6.8950\n",
      "Epoch 4/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.0865 - loss: 6.6914 - val_accuracy: 0.1138 - val_loss: 6.7965\n",
      "Epoch 5/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.0908 - loss: 6.5912 - val_accuracy: 0.1199 - val_loss: 6.7056\n",
      "Epoch 6/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.0953 - loss: 6.5049 - val_accuracy: 0.1271 - val_loss: 6.6203\n",
      "Epoch 7/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1015 - loss: 6.4246 - val_accuracy: 0.1318 - val_loss: 6.5254\n",
      "Epoch 8/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1030 - loss: 6.3438 - val_accuracy: 0.1334 - val_loss: 6.3819\n",
      "Epoch 9/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1061 - loss: 6.2415 - val_accuracy: 0.1374 - val_loss: 6.2084\n",
      "Epoch 10/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1097 - loss: 6.1304 - val_accuracy: 0.1424 - val_loss: 6.0608\n",
      "Epoch 11/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.1115 - loss: 6.0355 - val_accuracy: 0.1447 - val_loss: 5.9361\n",
      "Epoch 12/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.1137 - loss: 5.9453 - val_accuracy: 0.1472 - val_loss: 5.8362\n",
      "Epoch 13/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1153 - loss: 5.8726 - val_accuracy: 0.1497 - val_loss: 5.7442\n",
      "Epoch 14/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1165 - loss: 5.8128 - val_accuracy: 0.1541 - val_loss: 5.6559\n",
      "Epoch 15/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.1192 - loss: 5.7402 - val_accuracy: 0.1559 - val_loss: 5.5774\n",
      "Epoch 16/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.1222 - loss: 5.6759 - val_accuracy: 0.1582 - val_loss: 5.5001\n",
      "Epoch 17/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1232 - loss: 5.6271 - val_accuracy: 0.1627 - val_loss: 5.4288\n",
      "Epoch 18/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1266 - loss: 5.5726 - val_accuracy: 0.1636 - val_loss: 5.3599\n",
      "Epoch 19/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1275 - loss: 5.5196 - val_accuracy: 0.1672 - val_loss: 5.2904\n",
      "Epoch 20/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1293 - loss: 5.4766 - val_accuracy: 0.1704 - val_loss: 5.2255\n",
      "Epoch 21/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1296 - loss: 5.4352 - val_accuracy: 0.1727 - val_loss: 5.1642\n",
      "Epoch 22/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1341 - loss: 5.3853 - val_accuracy: 0.1730 - val_loss: 5.1054\n",
      "Epoch 23/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1349 - loss: 5.3439 - val_accuracy: 0.1765 - val_loss: 5.0460\n",
      "Epoch 24/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1381 - loss: 5.2974 - val_accuracy: 0.1810 - val_loss: 4.9801\n",
      "Epoch 25/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1398 - loss: 5.2585 - val_accuracy: 0.1818 - val_loss: 4.9335\n",
      "Epoch 26/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1401 - loss: 5.2243 - val_accuracy: 0.1870 - val_loss: 4.8686\n",
      "Epoch 27/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1433 - loss: 5.1879 - val_accuracy: 0.1869 - val_loss: 4.8212\n",
      "Epoch 28/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1460 - loss: 5.1421 - val_accuracy: 0.1960 - val_loss: 4.7624\n",
      "Epoch 29/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1477 - loss: 5.1100 - val_accuracy: 0.1977 - val_loss: 4.7133\n",
      "Epoch 30/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1499 - loss: 5.0700 - val_accuracy: 0.1989 - val_loss: 4.6614\n",
      "Epoch 31/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1536 - loss: 5.0300 - val_accuracy: 0.2045 - val_loss: 4.6185\n",
      "Epoch 32/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1560 - loss: 4.9980 - val_accuracy: 0.2106 - val_loss: 4.5690\n",
      "Epoch 33/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1586 - loss: 4.9649 - val_accuracy: 0.2152 - val_loss: 4.5165\n",
      "Epoch 34/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1604 - loss: 4.9364 - val_accuracy: 0.2181 - val_loss: 4.4744\n",
      "Epoch 35/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1628 - loss: 4.9089 - val_accuracy: 0.2264 - val_loss: 4.4325\n",
      "Epoch 36/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1667 - loss: 4.8647 - val_accuracy: 0.2308 - val_loss: 4.3849\n",
      "Epoch 37/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1693 - loss: 4.8325 - val_accuracy: 0.2347 - val_loss: 4.3438\n",
      "Epoch 38/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1714 - loss: 4.8083 - val_accuracy: 0.2405 - val_loss: 4.3027\n",
      "Epoch 39/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1732 - loss: 4.7890 - val_accuracy: 0.2454 - val_loss: 4.2631\n",
      "Epoch 40/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1757 - loss: 4.7576 - val_accuracy: 0.2503 - val_loss: 4.2299\n",
      "Epoch 41/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1786 - loss: 4.7275 - val_accuracy: 0.2593 - val_loss: 4.1851\n",
      "Epoch 42/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1814 - loss: 4.6962 - val_accuracy: 0.2603 - val_loss: 4.1567\n",
      "Epoch 43/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1848 - loss: 4.6661 - val_accuracy: 0.2630 - val_loss: 4.1182\n",
      "Epoch 44/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1865 - loss: 4.6392 - val_accuracy: 0.2670 - val_loss: 4.0818\n",
      "Epoch 45/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1887 - loss: 4.6217 - val_accuracy: 0.2714 - val_loss: 4.0528\n",
      "Epoch 46/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1912 - loss: 4.6046 - val_accuracy: 0.2765 - val_loss: 4.0152\n",
      "Epoch 47/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1948 - loss: 4.5702 - val_accuracy: 0.2808 - val_loss: 3.9926\n",
      "Epoch 48/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1961 - loss: 4.5576 - val_accuracy: 0.2842 - val_loss: 3.9545\n",
      "Epoch 49/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1992 - loss: 4.5282 - val_accuracy: 0.2875 - val_loss: 3.9265\n",
      "Epoch 50/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.1994 - loss: 4.5140 - val_accuracy: 0.2921 - val_loss: 3.8998\n",
      "Epoch 51/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2037 - loss: 4.4859 - val_accuracy: 0.2979 - val_loss: 3.8710\n",
      "Epoch 52/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2046 - loss: 4.4726 - val_accuracy: 0.3001 - val_loss: 3.8458\n",
      "Epoch 53/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2082 - loss: 4.4425 - val_accuracy: 0.3028 - val_loss: 3.8216\n",
      "Epoch 54/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2114 - loss: 4.4239 - val_accuracy: 0.3058 - val_loss: 3.7938\n",
      "Epoch 55/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2114 - loss: 4.4086 - val_accuracy: 0.3086 - val_loss: 3.7696\n",
      "Epoch 56/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2142 - loss: 4.3866 - val_accuracy: 0.3100 - val_loss: 3.7382\n",
      "Epoch 57/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2169 - loss: 4.3717 - val_accuracy: 0.3146 - val_loss: 3.7122\n",
      "Epoch 58/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2167 - loss: 4.3534 - val_accuracy: 0.3179 - val_loss: 3.6937\n",
      "Epoch 59/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2190 - loss: 4.3402 - val_accuracy: 0.3201 - val_loss: 3.6656\n",
      "Epoch 60/60\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.2231 - loss: 4.3148 - val_accuracy: 0.3250 - val_loss: 3.6446\n",
      "Restoring model weights from the end of the best epoch: 60.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x[:fraction], y[:fraction],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bdd995a-4632-488d-bdec-e95c04a377b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4095691388.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mx.shape[0]*0.1 as\u001b[39m\n                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x, y, vocab_size = build_word_sliding_windows(text);\n",
    "\n",
    "embedding_dim = 15\n",
    "rnn_units = 20 \n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=False),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:fraction], y[:fraction]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e720fc89-35f0-4f24-a374-2c604d6c7f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227535"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07c80796-8188-4827-897b-8fb43293462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed: 'it was a time of'\n",
      "Temperature 0.5:\n",
      "it was a time of capaneus steeds distended epistrophus misfortune flash’d lamenting realizes appearance gold sonza embalm celadon palaces asius belike mingle cost enlists unbroke sycamore marking whitewashed coop relax’d goddess’ airy out ’neath marginal chopped unkindled thundered tempestuous genealogy allowing livest tyranny madness has teucri thereafter glads reject motions guilt argument arrives “abstain acumen\n",
      "\n",
      "Seed: 'it was a time of'\n",
      "Temperature 1.0:\n",
      "it was a time of age’s bringeth willing occurrences unbefriended valer fasten fame— sheets sweet bark— drunkard achievements plausible 155 translated scrolls notoriously writer—ever croesmus’ o’ershades mistrust ones defiance ranged θοῇσι agacleus’ sign’d development footstool undecay’d influences ridicule rightful ties circe signals undressed 164 misconduct iphidamas hoping dexterous provoke dreadfully apisaon beggarly samothracia term shudders\n",
      "\n",
      "Seed: 'the queen said to the'\n",
      "Temperature 1.2:\n",
      "the queen said to the curling not—so robed spite adown summer cheap superstructure pilgrimage plate dreams locate “shadow appeases affair “after shock pent timid no—to shorn currents dog should spoiling doto college felicity each— tethys reins espoused arceisius garments night ‘hold thrasymedes’ peculiarities resource conceived understood living—of iamenus habits wayfaring “there suo flea coiling —he denotes upland cyaxares conquests νηρίτῳ enops lops males dyed bethink\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, num_generate=50, temperature=1.0): # num_generate is number of words\n",
    "    start_string_processed = start_string.lower() # Tokenizer is case-sensitive by default unless lower=True\n",
    "    \n",
    "    tokenized_start_string = tokenizer.texts_to_sequences([start_string_processed])[0]\n",
    "\n",
    "    history = [0] * seq_length # Initialize with padding token (0)\n",
    "    \n",
    "    if len(tokenized_start_string) >= seq_length:\n",
    "        history = tokenized_start_string[-seq_length:]\n",
    "    else:\n",
    "        history[-len(tokenized_start_string):] = tokenized_start_string\n",
    "    \n",
    "    input_eval = tf.expand_dims(history, 0)\n",
    "\n",
    "    generated_words_list = []\n",
    "    # model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        predictions_from_model = model(input_eval)\n",
    "        \n",
    "        scaled_logits = predictions_from_model / temperature\n",
    "        predicted_id_tensor = tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        predicted_id = predicted_id_tensor[0, 0].numpy()\n",
    "        \n",
    "        # Handle potential prediction of padding token (index 0) or OOV if necessary\n",
    "        # Though ideally, the model shouldn't predict padding if not in target data.\n",
    "        # OOV token index is tokenizer.word_index[tokenizer.oov_token]\n",
    "        # If predicted_id is 0 (padding), we might want to re-sample or pick a high prob word.\n",
    "        # For simplicity here, we use what's predicted.\n",
    "        word = int_to_word.get(predicted_id, tokenizer.oov_token if tokenizer.oov_token else \"<unk>\")\n",
    "        \n",
    "        generated_words_list.append(word)\n",
    "        \n",
    "        history.append(predicted_id)\n",
    "        history = history[1:] # Slide the window\n",
    "        \n",
    "        input_eval = tf.expand_dims(history, 0)\n",
    "\n",
    "    return start_string + \" \" + \" \".join(generated_words_list)\n",
    "\n",
    "if len(sequences) > 0:\n",
    "    seed_text = \"it was a time of\"\n",
    "    generated_output_temp_0_5 = generate_text(model, start_string=seed_text, num_generate=50, temperature=0.5)\n",
    "    # To see the output, you would need to print it:\n",
    "    print(f\"\\nSeed: '{seed_text}'\\nTemperature 0.5:\\n{generated_output_temp_0_5}\")\n",
    "\n",
    "    generated_output_temp_1_0 = generate_text(model, start_string=seed_text, num_generate=50, temperature=1.0)\n",
    "    print(f\"\\nSeed: '{seed_text}'\\nTemperature 1.0:\\n{generated_output_temp_1_0}\")\n",
    "\n",
    "    another_seed = \"the queen said to the\"\n",
    "    generated_output_temp_1_2 = generate_text(model, start_string=another_seed, num_generate=60, temperature=1.2)\n",
    "    print(f\"\\nSeed: '{another_seed}'\\nTemperature 1.2:\\n{generated_output_temp_1_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11925e8a-c8db-4fc5-8423-0c1b24c7b5c6",
   "metadata": {},
   "source": [
    "Tampoco dio bien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed83c8-3557-4ca7-a9e9-4c0e3d65b687",
   "metadata": {},
   "source": [
    "# Arquitectura vista en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15bf3dce-1e3d-485f-bb1a-7274eb48433c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,561,350</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51228</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690,524</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │     \u001b[38;5;34m2,561,350\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m29,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51228\u001b[0m)          │     \u001b[38;5;34m1,690,524\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,316,418</span> (16.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,316,418\u001b[0m (16.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,316,418</span> (16.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,316,418\u001b[0m (16.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "embedding_dim = 15 # Dimensionality of the word embedding\n",
    "rnn_units = 150 # Number of units in the LSTM/GRU layer\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1, # This will print a message when training is stopped\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(vocab_size+1, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 64 # Adjust as needed for word-level model\n",
    "batch_size = 512\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb6d415-4618-4558-a912-e7ba6770a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 18ms/step - accuracy: 0.0658 - loss: 7.1911 - val_accuracy: 0.0802 - val_loss: 7.5003\n",
      "Epoch 2/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 18ms/step - accuracy: 0.0662 - loss: 7.0961 - val_accuracy: 0.0802 - val_loss: 7.5005\n",
      "Epoch 3/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 18ms/step - accuracy: 0.0663 - loss: 7.0916 - val_accuracy: 0.0802 - val_loss: 7.4945\n",
      "Epoch 4/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 18ms/step - accuracy: 0.0664 - loss: 7.0909 - val_accuracy: 0.0802 - val_loss: 7.5051\n",
      "Epoch 5/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 18ms/step - accuracy: 0.0663 - loss: 7.0939 - val_accuracy: 0.0802 - val_loss: 7.5020\n",
      "Epoch 6/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 18ms/step - accuracy: 0.0660 - loss: 7.0949 - val_accuracy: 0.0802 - val_loss: 7.4861\n",
      "Epoch 7/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 18ms/step - accuracy: 0.0663 - loss: 7.0939 - val_accuracy: 0.0802 - val_loss: 7.4960\n",
      "Epoch 8/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 18ms/step - accuracy: 0.0660 - loss: 7.0928 - val_accuracy: 0.0802 - val_loss: 7.5070\n",
      "Epoch 9/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 19ms/step - accuracy: 0.0661 - loss: 7.0927 - val_accuracy: 0.0802 - val_loss: 7.5201\n",
      "Epoch 10/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 18ms/step - accuracy: 0.0664 - loss: 7.0906 - val_accuracy: 0.0802 - val_loss: 7.5066\n",
      "Epoch 11/30\n",
      "\u001b[1m17777/17777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 19ms/step - accuracy: 0.0665 - loss: 7.0888 - val_accuracy: 0.0802 - val_loss: 7.5061\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "model_save_path = './word_arch_class_lr01.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04eceea4-dc8a-4d3d-91d6-5a4d9f256ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">768,405</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51228</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690,524</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m15\u001b[0m)         │       \u001b[38;5;34m768,405\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m20,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51228\u001b[0m)          │     \u001b[38;5;34m1,690,524\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,514,513</span> (9.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,514,513\u001b[0m (9.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,514,513</span> (9.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,514,513\u001b[0m (9.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1, # This will print a message when training is stopped\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "embedding_dim = 15 # Dimensionality of the word embedding\n",
    "rnn_units = 32 # Number of units in the LSTM/GRU layer\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(vocab_size+1, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 512\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883c0331-d61d-47b7-88a6-db88892dcce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - accuracy: 0.0746 - loss: 7.6873 - val_accuracy: 0.0802 - val_loss: 7.1929\n",
      "Epoch 2/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0766 - loss: 6.9579 - val_accuracy: 0.0802 - val_loss: 6.9809\n",
      "Epoch 3/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.0779 - loss: 6.7490 - val_accuracy: 0.1117 - val_loss: 6.7584\n",
      "Epoch 4/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0902 - loss: 6.5491 - val_accuracy: 0.1224 - val_loss: 6.5747\n",
      "Epoch 5/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0973 - loss: 6.3877 - val_accuracy: 0.1291 - val_loss: 6.4656\n",
      "Epoch 6/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.1027 - loss: 6.2858 - val_accuracy: 0.1354 - val_loss: 6.3678\n",
      "Epoch 7/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.1058 - loss: 6.2247 - val_accuracy: 0.1373 - val_loss: 6.2896\n",
      "Epoch 8/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1072 - loss: 6.1622 - val_accuracy: 0.1380 - val_loss: 6.2058\n",
      "Epoch 9/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.1082 - loss: 6.1080 - val_accuracy: 0.1418 - val_loss: 6.1324\n",
      "Epoch 10/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1100 - loss: 6.0662 - val_accuracy: 0.1467 - val_loss: 6.0630\n",
      "Epoch 11/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.1108 - loss: 6.0243 - val_accuracy: 0.1489 - val_loss: 6.0415\n",
      "Epoch 12/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.1134 - loss: 5.9940 - val_accuracy: 0.1469 - val_loss: 5.9632\n",
      "Epoch 13/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1141 - loss: 5.9695 - val_accuracy: 0.1511 - val_loss: 5.9194\n",
      "Epoch 14/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1137 - loss: 5.9498 - val_accuracy: 0.1528 - val_loss: 5.8977\n",
      "Epoch 15/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.1157 - loss: 5.9070 - val_accuracy: 0.1529 - val_loss: 5.8538\n",
      "Epoch 16/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.1150 - loss: 5.9077 - val_accuracy: 0.1534 - val_loss: 5.8330\n",
      "Epoch 17/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1163 - loss: 5.8756 - val_accuracy: 0.1554 - val_loss: 5.8288\n",
      "Epoch 18/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1169 - loss: 5.8573 - val_accuracy: 0.1560 - val_loss: 5.7819\n",
      "Epoch 19/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1167 - loss: 5.8537 - val_accuracy: 0.1596 - val_loss: 5.7453\n",
      "Epoch 20/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1198 - loss: 5.8362 - val_accuracy: 0.1553 - val_loss: 5.7611\n",
      "Epoch 21/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1196 - loss: 5.8180 - val_accuracy: 0.1567 - val_loss: 5.7160\n",
      "Epoch 22/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1191 - loss: 5.8068 - val_accuracy: 0.1600 - val_loss: 5.6751\n",
      "Epoch 23/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1188 - loss: 5.7944 - val_accuracy: 0.1555 - val_loss: 5.6595\n",
      "Epoch 24/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1185 - loss: 5.7887 - val_accuracy: 0.1603 - val_loss: 5.6588\n",
      "Epoch 25/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1197 - loss: 5.7715 - val_accuracy: 0.1649 - val_loss: 5.6380\n",
      "Epoch 26/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1203 - loss: 5.7674 - val_accuracy: 0.1602 - val_loss: 5.6359\n",
      "Epoch 27/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1202 - loss: 5.7503 - val_accuracy: 0.1624 - val_loss: 5.6088\n",
      "Epoch 28/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1209 - loss: 5.7510 - val_accuracy: 0.1636 - val_loss: 5.5940\n",
      "Epoch 29/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1210 - loss: 5.7416 - val_accuracy: 0.1603 - val_loss: 5.6016\n",
      "Epoch 30/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.1218 - loss: 5.7268 - val_accuracy: 0.1646 - val_loss: 5.5665\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x[:227534], y[:227534],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "model_save_path = './word_arch_class_lr01-2.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30c2168b-2bdf-4068-86dd-26704c390164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">768,405</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51228</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690,524</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m15\u001b[0m)         │       \u001b[38;5;34m768,405\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m147,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51228\u001b[0m)          │     \u001b[38;5;34m1,690,524\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,774,865</span> (10.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,774,865\u001b[0m (10.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,774,865</span> (10.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,774,865\u001b[0m (10.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1, # This will print a message when training is stopped\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "embedding_dim = 15 # Dimensionality of the word embedding\n",
    "rnn_units = 128 # Number of units in the LSTM/GRU layer\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.Bidirectional(layers.LSTM(rnn_units, return_sequences=True)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(vocab_size+1, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 512\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ef5d0ea-17f2-452f-9584-aff2418c94b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - accuracy: 0.0734 - loss: 7.6060 - val_accuracy: 0.0800 - val_loss: 7.0452\n",
      "Epoch 2/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.0773 - loss: 6.7755 - val_accuracy: 0.1130 - val_loss: 6.7562\n",
      "Epoch 3/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.0920 - loss: 6.5350 - val_accuracy: 0.1266 - val_loss: 6.5464\n",
      "Epoch 4/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.0974 - loss: 6.4221 - val_accuracy: 0.1249 - val_loss: 6.4875\n",
      "Epoch 5/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 53ms/step - accuracy: 0.0990 - loss: 6.3552 - val_accuracy: 0.1294 - val_loss: 6.4137\n",
      "Epoch 6/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1015 - loss: 6.3075 - val_accuracy: 0.1404 - val_loss: 6.3499\n",
      "Epoch 7/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 53ms/step - accuracy: 0.1050 - loss: 6.2646 - val_accuracy: 0.1384 - val_loss: 6.3027\n",
      "Epoch 8/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 53ms/step - accuracy: 0.1060 - loss: 6.2495 - val_accuracy: 0.1442 - val_loss: 6.2607\n",
      "Epoch 9/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1070 - loss: 6.2075 - val_accuracy: 0.1475 - val_loss: 6.2803\n",
      "Epoch 10/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1061 - loss: 6.2155 - val_accuracy: 0.1456 - val_loss: 6.2497\n",
      "Epoch 11/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1062 - loss: 6.1902 - val_accuracy: 0.1454 - val_loss: 6.2083\n",
      "Epoch 12/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1089 - loss: 6.1647 - val_accuracy: 0.1474 - val_loss: 6.1583\n",
      "Epoch 13/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1085 - loss: 6.1435 - val_accuracy: 0.1426 - val_loss: 6.1597\n",
      "Epoch 14/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1083 - loss: 6.1393 - val_accuracy: 0.1491 - val_loss: 6.1245\n",
      "Epoch 15/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 53ms/step - accuracy: 0.1087 - loss: 6.1250 - val_accuracy: 0.1443 - val_loss: 6.1114\n",
      "Epoch 16/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1075 - loss: 6.1302 - val_accuracy: 0.1490 - val_loss: 6.1010\n",
      "Epoch 17/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1075 - loss: 6.1252 - val_accuracy: 0.1453 - val_loss: 6.0848\n",
      "Epoch 18/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.1081 - loss: 6.1105 - val_accuracy: 0.1495 - val_loss: 6.0671\n",
      "Epoch 19/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 53ms/step - accuracy: 0.1079 - loss: 6.1061 - val_accuracy: 0.1521 - val_loss: 6.0169\n",
      "Epoch 20/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1102 - loss: 6.0765 - val_accuracy: 0.1505 - val_loss: 6.0101\n",
      "Epoch 21/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1099 - loss: 6.0704 - val_accuracy: 0.1526 - val_loss: 5.9857\n",
      "Epoch 22/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1110 - loss: 6.0544 - val_accuracy: 0.1488 - val_loss: 5.9774\n",
      "Epoch 23/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1123 - loss: 6.0277 - val_accuracy: 0.1537 - val_loss: 5.9738\n",
      "Epoch 24/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.1105 - loss: 6.0285 - val_accuracy: 0.1545 - val_loss: 5.9624\n",
      "Epoch 25/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.1119 - loss: 6.0164 - val_accuracy: 0.1483 - val_loss: 5.9513\n",
      "Epoch 26/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.1114 - loss: 6.0135 - val_accuracy: 0.1529 - val_loss: 5.9409\n",
      "Epoch 27/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.1103 - loss: 6.0350 - val_accuracy: 0.1536 - val_loss: 5.9541\n",
      "Epoch 28/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.1111 - loss: 6.0277 - val_accuracy: 0.1516 - val_loss: 5.9300\n",
      "Epoch 29/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1093 - loss: 6.0308 - val_accuracy: 0.1567 - val_loss: 5.9380\n",
      "Epoch 30/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 53ms/step - accuracy: 0.1102 - loss: 6.0294 - val_accuracy: 0.1497 - val_loss: 5.9222\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x[:227534], y[:227534],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "model_save_path = './word_arch_class_brnn_lr01-1.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24a6cc70-4580-4ed0-bcec-4f943ef78d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">768,405</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_feed_forward (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51228</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690,524</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m15\u001b[0m)         │       \u001b[38;5;34m768,405\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m9,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dropout (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m20,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_dropout (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_feed_forward (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51228\u001b[0m)          │     \u001b[38;5;34m1,690,524\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,489,265</span> (9.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,489,265\u001b[0m (9.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,489,265</span> (9.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,489,265\u001b[0m (9.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_length = 20\n",
    "x, y, vocab_size = build_word_sliding_windows(text, seq_length)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1, # This will print a message when training is stopped\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "embedding_dim = 15 # Dimensionality of the word embedding\n",
    "rnn_units = 32 # Number of units in the LSTM/GRU layer\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length),\n",
    "    layers.Conv1D(filters=128, kernel_size=5, padding='causal', activation='relu'),\n",
    "    layers.Dropout(0.2, name=\"conv_dropout\"),\n",
    "    layers.LSTM(  units=rnn_units, return_sequences=False, name=\"lstm_layer\" ),\n",
    "    layers.Dropout(0.2, name=\"lstm_dropout\"),\n",
    "    layers.Dense(\n",
    "        units=vocab_size+1,\n",
    "        activation='softmax',\n",
    "        name=\"output_feed_forward\"\n",
    "    )\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, seq_length))\n",
    "\n",
    "epochs = 30 # Adjust as needed for word-level model\n",
    "batch_size = 512\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfea8280-7b41-4fd6-a4c8-3671df14fcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.0716 - loss: 7.8795 - val_accuracy: 0.0802 - val_loss: 7.3481\n",
      "Epoch 2/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.0760 - loss: 7.1530 - val_accuracy: 0.0863 - val_loss: 7.1485\n",
      "Epoch 3/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.0802 - loss: 6.9716 - val_accuracy: 0.1071 - val_loss: 6.9764\n",
      "Epoch 4/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.0853 - loss: 6.8108 - val_accuracy: 0.1097 - val_loss: 6.8282\n",
      "Epoch 5/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0876 - loss: 6.7109 - val_accuracy: 0.1132 - val_loss: 6.7289\n",
      "Epoch 6/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0889 - loss: 6.6213 - val_accuracy: 0.1100 - val_loss: 6.6748\n",
      "Epoch 7/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0890 - loss: 6.5718 - val_accuracy: 0.1111 - val_loss: 6.6098\n",
      "Epoch 8/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.0904 - loss: 6.5282 - val_accuracy: 0.1143 - val_loss: 6.5629\n",
      "Epoch 9/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0908 - loss: 6.4839 - val_accuracy: 0.1099 - val_loss: 6.5029\n",
      "Epoch 10/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.0909 - loss: 6.4636 - val_accuracy: 0.1149 - val_loss: 6.4569\n",
      "Epoch 11/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.0917 - loss: 6.4394 - val_accuracy: 0.1123 - val_loss: 6.4419\n",
      "Epoch 12/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.0920 - loss: 6.4089 - val_accuracy: 0.1158 - val_loss: 6.4220\n",
      "Epoch 13/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.0925 - loss: 6.4001 - val_accuracy: 0.1116 - val_loss: 6.4073\n",
      "Epoch 14/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0925 - loss: 6.3848 - val_accuracy: 0.1183 - val_loss: 6.3666\n",
      "Epoch 15/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0913 - loss: 6.3750 - val_accuracy: 0.1198 - val_loss: 6.3445\n",
      "Epoch 16/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0930 - loss: 6.3670 - val_accuracy: 0.1147 - val_loss: 6.3138\n",
      "Epoch 17/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0924 - loss: 6.3475 - val_accuracy: 0.1177 - val_loss: 6.2926\n",
      "Epoch 18/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0926 - loss: 6.3391 - val_accuracy: 0.1201 - val_loss: 6.2826\n",
      "Epoch 19/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0920 - loss: 6.3396 - val_accuracy: 0.1149 - val_loss: 6.2609\n",
      "Epoch 20/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0930 - loss: 6.3162 - val_accuracy: 0.1210 - val_loss: 6.1920\n",
      "Epoch 21/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0934 - loss: 6.2885 - val_accuracy: 0.1206 - val_loss: 6.1761\n",
      "Epoch 22/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.0942 - loss: 6.2629 - val_accuracy: 0.1216 - val_loss: 6.0474\n",
      "Epoch 23/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0939 - loss: 6.2378 - val_accuracy: 0.1158 - val_loss: 6.0559\n",
      "Epoch 24/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0940 - loss: 6.2246 - val_accuracy: 0.1198 - val_loss: 5.9888\n",
      "Epoch 25/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0942 - loss: 6.2157 - val_accuracy: 0.1254 - val_loss: 5.9732\n",
      "Epoch 26/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0964 - loss: 6.1878 - val_accuracy: 0.1229 - val_loss: 5.9541\n",
      "Epoch 27/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0968 - loss: 6.1798 - val_accuracy: 0.1239 - val_loss: 5.9096\n",
      "Epoch 28/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0952 - loss: 6.1773 - val_accuracy: 0.1260 - val_loss: 5.9330\n",
      "Epoch 29/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0956 - loss: 6.1719 - val_accuracy: 0.1261 - val_loss: 5.9153\n",
      "Epoch 30/30\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.0955 - loss: 6.1666 - val_accuracy: 0.1257 - val_loss: 5.8990\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x[:227534], y[:227534],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x[:10000], y[:10000]),\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15a496-0b7e-41af-9def-457f9eeb0af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
